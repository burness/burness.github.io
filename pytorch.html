<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  pytorch - 小石头的码疯窝
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="小石头的码疯窝" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
 
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 小石头的码疯窝</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html">推荐系统</a></li>
        
            <li><a href="TensorFlow.html">TensorFlow</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0.html">机器学习平台</a></li>
        
            <li><a href="%E5%9B%BE%E8%AE%A1%E7%AE%97.html">图计算</a></li>
        
            <li><a href="pytorch.html">pytorch</a></li>
        
            <li><a href="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F.html">分布式系统</a></li>
        
            <li><a href="mlops.html">mlops</a></li>
        
            <li><a href="paddle.html">paddle</a></li>
        
            <li><a href="%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8.html">参数服务器</a></li>
        
            <li><a href="GAN.html">GAN</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15808187045354.html">
                
                  <h1>pytorch 环境安装及配置</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>基础的cuda 啥的就不详细描述了，建议用docker、建议用docker、建议用docker，把搞环境的时间花在跑代码上不香吗？ 本文主要是来自于pytorch 官网，会稍微改下部分内容来作为学习笔记；</p>
<pre><code class="language-python"># install pytorch 1.4
!pip install -U torch torchvision -i https://mirrors.aliyun.com/pypi/simple
</code></pre>
<pre><code>Looking in indexes: https://mirrors.aliyun.com/pypi/simple
Collecting torch
  Using cached https://mirrors.aliyun.com/pypi/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)
Collecting torchvision
  Using cached https://mirrors.aliyun.com/pypi/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)
Requirement already satisfied, skipping upgrade: six in /app/anaconda3/lib/python3.7/site-packages (from torchvision) (1.12.0)
Requirement already satisfied, skipping upgrade: pillow&gt;=4.1.1 in /app/anaconda3/lib/python3.7/site-packages (from torchvision) (6.2.0)
Requirement already satisfied, skipping upgrade: numpy in /app/anaconda3/lib/python3.7/site-packages (from torchvision) (1.17.2)
Installing collected packages: torch, torchvision
Successfully installed torch-1.4.0 torchvision-0.5.0
</code></pre>
<pre><code class="language-python"># verification
from __future__ import print_function
import torch
x = torch.rand(5, 3)
print(x)
</code></pre>
<pre><code>tensor([[0.3890, 0.3672, 0.2697],
        [0.1633, 0.1091, 0.9061],
        [0.0438, 0.5167, 0.5995],
        [0.0546, 0.0019, 0.8384],
        [0.5708, 0.0217, 0.3954]])
</code></pre>
<pre><code class="language-python"># check gpu device
import torch
torch.cuda.is_available()
</code></pre>
<pre><code>True
</code></pre>
<h1><a id="what-is-pytorch" class="anchor" aria-hidden="true" href="#what-is-pytorch"><span class="octicon octicon-link"></span></a>what is pytorch</h1>
<h2><a id="tensors" class="anchor" aria-hidden="true" href="#tensors"><span class="octicon octicon-link"></span></a>Tensors</h2>
<pre><code class="language-python">from __future__ import print_function
import torch
x = torch.empty(5, 3)
print(x)
x = torch.rand(5, 3)
print(x)
x = torch.zeros(5, 3, dtype=torch.long)
print(x)
x = torch.tensor([5.5, 3])
print(x)
x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes
print(x)
x = torch.randn_like(x, dtype=torch.float)    # override dtype!
print(x)    
print(x.size())
</code></pre>
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
tensor([[0.5029, 0.7441, 0.5813],
        [0.1014, 0.4897, 0.2367],
        [0.2384, 0.6276, 0.0321],
        [0.9223, 0.4334, 0.9809],
        [0.1237, 0.3212, 0.0656]])
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
tensor([5.5000, 3.0000])
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
tensor([[ 0.5468, -0.4615, -0.0450],
        [ 0.5001, -0.9717, -0.6103],
        [-0.5345,  0.1126, -0.0836],
        [-0.5534,  0.5423, -1.1128],
        [-1.3799,  1.3353, -1.6969]])
torch.Size([5, 3])
</code></pre>
<h2><a id="operaations" class="anchor" aria-hidden="true" href="#operaations"><span class="octicon octicon-link"></span></a>Operaations</h2>
<pre><code class="language-python">y = torch.rand(5, 3)
print(x+y)
</code></pre>
<pre><code>tensor([[ 1.0743, -0.4365,  0.7751],
        [ 1.4214, -0.7803, -0.2535],
        [ 0.3591,  0.7957,  0.0637],
        [-0.3185,  0.5621, -0.9368],
        [-0.7098,  1.5445, -1.5394]])
</code></pre>
<pre><code class="language-python">print(torch.add(x, y))
</code></pre>
<pre><code>tensor([[ 1.0743, -0.4365,  0.7751],
        [ 1.4214, -0.7803, -0.2535],
        [ 0.3591,  0.7957,  0.0637],
        [-0.3185,  0.5621, -0.9368],
        [-0.7098,  1.5445, -1.5394]])
</code></pre>
<pre><code class="language-python">result = torch.empty(5, 3)
torch.add(x, y, out=result)
print(result)
</code></pre>
<pre><code>tensor([[ 1.0743, -0.4365,  0.7751],
        [ 1.4214, -0.7803, -0.2535],
        [ 0.3591,  0.7957,  0.0637],
        [-0.3185,  0.5621, -0.9368],
        [-0.7098,  1.5445, -1.5394]])
</code></pre>
<pre><code class="language-python"># Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.
y.add_(x)
print(y)
print(x[:, 1])
</code></pre>
<pre><code>tensor([[ 1.0743, -0.4365,  0.7751],
        [ 1.4214, -0.7803, -0.2535],
        [ 0.3591,  0.7957,  0.0637],
        [-0.3185,  0.5621, -0.9368],
        [-0.7098,  1.5445, -1.5394]])
tensor([-0.4615, -0.9717,  0.1126,  0.5423,  1.3353])
</code></pre>
<pre><code class="language-python"># Resizing: If you want to resize/reshape tensor, you can use torch.view:

x = torch.randn(4, 4)
y = x.view(16)
z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
print(x.size(), y.size(), z.size())
</code></pre>
<pre><code>torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])
</code></pre>
<pre><code class="language-python"># If you have a one element tensor, use .item() to get the value as a Python number
x = torch.randn(1)
print(x)
print(x.item())
</code></pre>
<pre><code>tensor([0.9993])
0.999320387840271
</code></pre>
<h2><a id="numpy-bridge" class="anchor" aria-hidden="true" href="#numpy-bridge"><span class="octicon octicon-link"></span></a>Numpy Bridge</h2>
<pre><code class="language-python"># Converting a Torch Tensor to a NumPy Array
a = torch.ones(5)
print(a)
b = a.numpy()
print(b)
a.add_(1)
print(a)
print(b)
</code></pre>
<pre><code>tensor([1., 1., 1., 1., 1.])
[1. 1. 1. 1. 1.]
tensor([2., 2., 2., 2., 2.])
[2. 2. 2. 2. 2.]
</code></pre>
<pre><code class="language-python"># Converting NumPy Array to Torch Tensor
import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
np.add(a, 1, out=a)
print(a)
print(b)
</code></pre>
<pre><code>[2. 2. 2. 2. 2.]
tensor([2., 2., 2., 2., 2.], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">## CUDA Tensors

if torch.cuda.is_available():
    device = torch.device(&quot;cuda&quot;)          # a CUDA device object
    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU
    x = x.to(device)                       # or just use strings ``.to(&quot;cuda&quot;)``
    z = x + y
    print(z)
    print(z.to(&quot;cpu&quot;, torch.double))       # ``.to`` can also change dtype together!
</code></pre>
<pre><code>tensor([1.9993], device='cuda:0')
tensor([1.9993], dtype=torch.float64)
</code></pre>
<h2><a id="autograd-automatic-differentiation" class="anchor" aria-hidden="true" href="#autograd-automatic-differentiation"><span class="octicon octicon-link"></span></a>AUTOGRAD: AUTOMATIC DIFFERENTIATION</h2>
<p>Central to all neural networks in PyTorch is the autograd package. Let’s first briefly visit this, and we will then go to training our first neural network.<br />
The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.</p>
<h2><a id="tensor" class="anchor" aria-hidden="true" href="#tensor"><span class="octicon octicon-link"></span></a>Tensor</h2>
<p><code>torch.Tensor</code> is the central class of the package. If you set its attribute <code>.requires_grad</code> as True, it starts to track all operations on it. When you finish your computation you can call <code>.backward()</code> and have all the gradients computed automatically. The gradient for this tensor will be accumulated into <code>.grad</code> attribute.</p>
<pre><code class="language-python">x = torch.ones(2, 2, requires_grad=True)
print(x)
y = x + 2
print(y)
print(y.grad_fn)
z = y * y * 3
out = z.mean()
print(z, out)
</code></pre>
<pre><code>tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
tensor([[3., 3.],
        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)
&lt;AddBackward0 object at 0x7feca614d6d0&gt;
tensor([[27., 27.],
        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)
</code></pre>
<pre><code class="language-python">a = torch.randn(2, 2)
a = ((a * 3) / (a - 1))
print(a.requires_grad)
a.requires_grad_(True)
print(a.requires_grad)
b = (a * a).sum()
print(b.grad_fn)
</code></pre>
<pre><code>False
True
&lt;SumBackward0 object at 0x7feca617ddd0&gt;
</code></pre>
<h2><a id="gradients" class="anchor" aria-hidden="true" href="#gradients"><span class="octicon octicon-link"></span></a>Gradients</h2>
<pre><code class="language-python">out.backward()
</code></pre>
<pre><code class="language-python">print(x.grad)
</code></pre>
<pre><code>tensor([[4.5000, 4.5000],
        [4.5000, 4.5000]])
</code></pre>
<pre><code class="language-python">x = torch.randn(3, requires_grad=True)
y = x * 2
while y.data.norm() &lt; 1000:
    y = y * 2
print(y)
</code></pre>
<pre><code>tensor([-1138.8549,   484.4676,   417.7082], grad_fn=&lt;MulBackward0&gt;)
</code></pre>
<pre><code class="language-python">v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)
y.backward(v)

print(x.grad)
</code></pre>
<pre><code>tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])
</code></pre>
<pre><code class="language-python"># stop autograd from tracking history on Tensors with .requires_grad=True either by wrapping the code block in with torch.no_grad():
print(x.requires_grad)
print((x ** 2).requires_grad)

with torch.no_grad():
    print((x ** 2).requires_grad)
    
# Or by using .detach() to get a new Tensor with the same content but that does not require gradients:
print(x.requires_grad)
y = x.detach()
print(y.requires_grad)
print(x.eq(y).all())
</code></pre>
<pre><code>True
True
False
True
False
tensor(True)
</code></pre>
<h2><a id="neural-networks" class="anchor" aria-hidden="true" href="#neural-networks"><span class="octicon octicon-link"></span></a>Neural networks</h2>
<p>A typical training procedure for a neural network is as follows:</p>
<ul>
<li>Define the neural network that has some learnable parameters (or weights)</li>
<li>Iterate over a dataset of inputs</li>
<li>Process input through the network</li>
<li>Compute the loss (how far is the output from being correct)</li>
<li>Propagate gradients back into the network’s parameters</li>
<li>Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient</li>
</ul>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        # 1 input image channel, 6 output channels, 3x3 square convolution
        # kernel
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        # an affine operation: y = Wx + b
        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # Max pooling over a (2, 2) window
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        # If the size is a square you can only specify a single number
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


net = Net()
print(net)
</code></pre>
<pre><code>Net(
  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=576, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
</code></pre>
<pre><code class="language-python">params = list(net.parameters())
print(len(params))
print(params[0].size())  # conv1's .weight
</code></pre>
<pre><code>10
torch.Size([6, 1, 3, 3])
</code></pre>
<pre><code class="language-python"># feed a random input
input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)
</code></pre>
<pre><code>tensor([[-0.0082, -0.0266,  0.0843,  0.0188,  0.1456, -0.1081, -0.0937,  0.0086,
         -0.0356,  0.0723]], grad_fn=&lt;AddmmBackward&gt;)
</code></pre>
<pre><code class="language-python"># Zero the gradient buffers of all parameters and backprops with random gradients:
net.zero_grad()
out.backward(torch.randn(1, 10))
</code></pre>
<h2><a id="loss-function" class="anchor" aria-hidden="true" href="#loss-function"><span class="octicon octicon-link"></span></a>Loss Function</h2>
<pre><code class="language-python">output = net(input)
target = torch.randn(10)  # a dummy target, for example
target = target.view(1, -1)  # make it the same shape as output
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)
</code></pre>
<pre><code>tensor(1.0206, grad_fn=&lt;MseLossBackward&gt;)
</code></pre>
<pre><code class="language-python">print(loss.grad_fn)  # MSELoss
print(loss.grad_fn.next_functions[0][0])  # Linear
print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU
</code></pre>
<pre><code>&lt;MseLossBackward object at 0x7fec9c351350&gt;
&lt;AddmmBackward object at 0x7feca617d490&gt;
&lt;AccumulateGrad object at 0x7fec9c351350&gt;
</code></pre>
<h2><a id="backprop" class="anchor" aria-hidden="true" href="#backprop"><span class="octicon octicon-link"></span></a>Backprop</h2>
<pre><code class="language-python">net.zero_grad()     # zeroes the gradient buffers of all parameters

print('conv1.bias.grad before backward')
print(net.conv1.bias.grad)

loss.backward()

print('conv1.bias.grad after backward')
print(net.conv1.bias.grad)
</code></pre>
<pre><code>conv1.bias.grad before backward
tensor([0., 0., 0., 0., 0., 0.])
conv1.bias.grad after backward
tensor([-0.0241, -0.0161, -0.0086, -0.0032,  0.0125,  0.0005])
</code></pre>
<h2><a id="update-the-weights" class="anchor" aria-hidden="true" href="#update-the-weights"><span class="octicon octicon-link"></span></a>Update the weights</h2>
<pre><code class="language-python"># using sgd
learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)

</code></pre>
<pre><code class="language-python"># using custom optimizer in torch.optim
import torch.optim as optim

# create your optimizer
optimizer = optim.SGD(net.parameters(), lr=0.01)

# in your training loop:
optimizer.zero_grad()   # zero the gradient buffers
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()    # Does the update
</code></pre>
<h2><a id="training-a-classifier" class="anchor" aria-hidden="true" href="#training-a-classifier"><span class="octicon octicon-link"></span></a>Training a classifier</h2>
<h2><a id="what-about-data" class="anchor" aria-hidden="true" href="#what-about-data"><span class="octicon octicon-link"></span></a>What about data?</h2>
<p>When you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a <code>torch.*Tensor</code>.</p>
<ul>
<li>For images, packages such as Pillow, OpenCV are usefu</li>
<li>For audio, packages such as scipy and librosa</li>
<li>For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful</li>
</ul>
<h2><a id="training-an-image-classifier" class="anchor" aria-hidden="true" href="#training-an-image-classifier"><span class="octicon octicon-link"></span></a>Training an image classifier</h2>
<ul>
<li>Load and normalizing the CIFAR10 training and test datasets using torchvision</li>
<li>Define a Convolutional Neural Network</li>
<li>Define a loss function</li>
<li>Train the network on the training data</li>
<li>Test the network on the test data</li>
</ul>
<h3><a id="loading-and-normalizing-cifar10" class="anchor" aria-hidden="true" href="#loading-and-normalizing-cifar10"><span class="octicon octicon-link"></span></a>Loading and normalizing CIFAR10</h3>
<pre><code class="language-python">import torch
import torchvision
import torchvision.transforms as transforms

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
</code></pre>
<pre><code>Files already downloaded and verified
Files already downloaded and verified
</code></pre>
<pre><code class="language-python">%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

# functions to show an image


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))

</code></pre>
<p><img src="media/15808187045354/output_49_0.png" alt="output_49_0" /></p>
<pre><code>  cat   cat  deer  ship
</code></pre>
<h3><a id="define-a-convolutional-neural-network" class="anchor" aria-hidden="true" href="#define-a-convolutional-neural-network"><span class="octicon octicon-link"></span></a>Define a Convolutional Neural Network</h3>
<pre><code class="language-python">import torch.nn.functional as F
import torch.nn as nn


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    
net = Net()
</code></pre>
<h3><a id="define-a-loss-function-and-optimizer" class="anchor" aria-hidden="true" href="#define-a-loss-function-and-optimizer"><span class="octicon octicon-link"></span></a>Define a Loss function and optimizer</h3>
<pre><code class="language-python">import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
</code></pre>
<h3><a id="train-the-network" class="anchor" aria-hidden="true" href="#train-the-network"><span class="octicon octicon-link"></span></a>Train the network</h3>
<pre><code class="language-python">for epoch in range(2):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader):
#         print(data)
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
#         print(inputs, labels)
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
</code></pre>
<pre><code>[1,  2000] loss: 2.203
[1,  4000] loss: 1.875
[1,  6000] loss: 1.680
[1,  8000] loss: 1.563
[1, 10000] loss: 1.480
[1, 12000] loss: 1.474
[2,  2000] loss: 1.397
[2,  4000] loss: 1.365
[2,  6000] loss: 1.350
[2,  8000] loss: 1.321
[2, 10000] loss: 1.302
[2, 12000] loss: 1.300
Finished Training
</code></pre>
<pre><code class="language-python">PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)
</code></pre>
<pre><code class="language-python">dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print(labels)
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
</code></pre>
<p><img src="media/15808187045354/output_57_0.png" alt="output_57_0" /></p>
<pre><code>tensor([3, 8, 8, 0])
GroundTruth:    cat  ship  ship plane
</code></pre>
<pre><code class="language-python">net = Net()
net.load_state_dict(torch.load(PATH))

</code></pre>
<pre><code>&lt;All keys matched successfully&gt;
</code></pre>
<pre><code class="language-python">outputs = net(images)
print(outputs)
_, predicted = torch.max(outputs, 1)
print(predicted)
print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
                              for j in range(4)))
</code></pre>
<pre><code>tensor([[-8.1609e-01, -7.3227e-01,  1.9178e-01,  1.9166e+00, -9.6811e-01,
          8.3362e-01,  1.1127e+00, -1.4818e+00,  3.7150e-01, -7.1563e-01],
        [ 7.2351e+00,  4.0154e+00,  1.7224e-03, -2.3247e+00, -2.0117e+00,
         -4.3768e+00, -4.1172e+00, -4.6825e+00,  8.7625e+00,  2.0940e+00],
        [ 3.9245e+00,  1.3894e+00,  6.4428e-01, -1.0531e+00, -8.4998e-01,
         -2.2757e+00, -2.7469e+00, -2.2073e+00,  4.4428e+00,  6.6101e-01],
        [ 4.5622e+00, -6.9576e-02,  1.1598e+00, -8.8092e-01,  9.0635e-01,
         -2.1905e+00, -1.8022e+00, -2.2323e+00,  4.0340e+00, -7.8086e-01]],
       grad_fn=&lt;AddmmBackward&gt;)
tensor([3, 8, 8, 0])
Predicted:    cat  ship  ship plane
</code></pre>
<pre><code class="language-python">correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
</code></pre>
<pre><code>Accuracy of the network on the 10000 test images: 55 %
</code></pre>
<pre><code class="language-python">class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
</code></pre>
<pre><code>Accuracy of plane : 66 %
Accuracy of   car : 59 %
Accuracy of  bird : 36 %
Accuracy of   cat : 38 %
Accuracy of  deer : 56 %
Accuracy of   dog : 27 %
Accuracy of  frog : 73 %
Accuracy of horse : 59 %
Accuracy of  ship : 72 %
Accuracy of truck : 63 %
</code></pre>
<h3><a id="training-on-gpu" class="anchor" aria-hidden="true" href="#training-on-gpu"><span class="octicon octicon-link"></span></a>Training on GPU</h3>
<pre><code class="language-python">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

# Assuming that we are on a CUDA machine, this should print a CUDA device:

print(device)
net.to(device)


for epoch in range(2):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader):
#         print(data)
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)
#         print(inputs, labels)
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
</code></pre>
<pre><code>cuda:0
[1,  2000] loss: 1.195
[1,  4000] loss: 1.204
[1,  6000] loss: 1.204
[1,  8000] loss: 1.188
[1, 10000] loss: 1.207
[1, 12000] loss: 1.228
[2,  2000] loss: 1.191
[2,  4000] loss: 1.209
[2,  6000] loss: 1.202
[2,  8000] loss: 1.209
[2, 10000] loss: 1.214
[2, 12000] loss: 1.203
Finished Training
</code></pre>
<pre><code class="language-python">net = Net()
net.load_state_dict(torch.load(PATH))

correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
</code></pre>
<pre><code>Accuracy of the network on the 10000 test images: 55 %
</code></pre>
<h2><a id="training-on-multi-gpus" class="anchor" aria-hidden="true" href="#training-on-multi-gpus"><span class="octicon octicon-link"></span></a>Training on multi gpus</h2>
<pre><code class="language-python">if torch.cuda.device_count() &gt; 1:
  print(&quot;Let's use&quot;, torch.cuda.device_count(), &quot;GPUs!&quot;)

net = nn.DataParallel(net)
net.to(device)
for epoch in range(4):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader):
#         print(data)
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)
#         print(inputs, labels)
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
</code></pre>
<pre><code>Let's use 2 GPUs!
[1,  2000] loss: 1.202
[1,  4000] loss: 1.197
[1,  6000] loss: 1.202
[1,  8000] loss: 1.194
[1, 10000] loss: 1.211
[1, 12000] loss: 1.210
[2,  2000] loss: 1.208
[2,  4000] loss: 1.184
[2,  6000] loss: 1.215
[2,  8000] loss: 1.198
[2, 10000] loss: 1.201
[2, 12000] loss: 1.208
[3,  2000] loss: 1.206
[3,  4000] loss: 1.209
[3,  6000] loss: 1.198
[3,  8000] loss: 1.206
[3, 10000] loss: 1.209
[3, 12000] loss: 1.208
[4,  2000] loss: 1.203
[4,  4000] loss: 1.206
[4,  6000] loss: 1.203
[4,  8000] loss: 1.187
[4, 10000] loss: 1.220
[4, 12000] loss: 1.207
Finished Training
</code></pre>
<p><img src="media/15808187045354/2_gpus.jpeg" alt="2_gpus" /></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2020/02/04</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='pytorch.html'>pytorch</a></span>
          				   
                    

                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <h1>小石头的码疯窝</h1>
                <div class="site-des">记录一些学习笔记</div>
                <div class="social">











  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html"><strong>推荐系统</strong></a>
        
            <a href="TensorFlow.html"><strong>TensorFlow</strong></a>
        
            <a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0.html"><strong>机器学习平台</strong></a>
        
            <a href="%E5%9B%BE%E8%AE%A1%E7%AE%97.html"><strong>图计算</strong></a>
        
            <a href="pytorch.html"><strong>pytorch</strong></a>
        
            <a href="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F.html"><strong>分布式系统</strong></a>
        
            <a href="mlops.html"><strong>mlops</strong></a>
        
            <a href="paddle.html"><strong>paddle</strong></a>
        
            <a href="%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8.html"><strong>参数服务器</strong></a>
        
            <a href="GAN.html"><strong>GAN</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="16533711069508.html">网易云音乐机器学习平台实践</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="16490569390259.html">模型生产环境中的反馈与数据回流</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="16482627913984.html">mlops之监控与数据回流</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="16371350579612.html">机器学习平台在云音乐的持续实践</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="16268581441013.html">为机器学习量身定做的ops工具：cml & dvc</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>



  














<style type="text/css">
figure{margin: 0;padding: 0;}
figcaption{text-align:center;}

/* PrismJS 1.14.0
 http://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    text-shadow: 0 1px white;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
    
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
    
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
    text-shadow: none;
    background:#b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
    text-shadow: none;
    background: #b3d4fc;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background: #F7F7F7;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: slategray;
}

.token.punctuation {
    color: #999;
}

.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #9a6e3a;
    background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #07a;
}

.token.function,
.token.class-name {
    color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
    color: #e90;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
    position: relative;
    padding-left: 3.8em;
    counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
    position: relative;
    white-space: inherit;
}

.line-numbers .line-numbers-rows {
    position: absolute;
    pointer-events: none;
    top: 0;
    font-size: 100%;
    left: -3.8em;
    width: 3em; /* works for line-numbers below 1000 lines */
    letter-spacing: -1px;
    border-right: 1px solid #999;

    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

}

    .line-numbers-rows > span {
        pointer-events: none;
        display: block;
        counter-increment: linenumber;
    }

        .line-numbers-rows > span:before {
            content: counter(linenumber);
            color: #999;
            display: block;
            padding-right: 0.8em;
            text-align: right;
        }

</style>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>



  </body>
</html>
