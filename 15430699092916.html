<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Maybe Best Practice With Sparse Machine Learning In TensorFlow - 
  
  </title>
 <meta name="description" content="">
 <link href="atom.xml" rel="alternate" title="" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html"></a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; </span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>推荐系统</label></li>

          
            <li><a title="推荐系统的禅与道" href="15951226773958.html">推荐系统的禅与道</a></li>
          
            <li><a title="推荐系统灌水文之如何理解Item" href="15763400595374.html">推荐系统灌水文之如何理解Item</a></li>
          

      
        <li class="divider"></li>
        <li><label>TensorFlow</label></li>

          
            <li><a title="TensorFlow Sparse的一个优化" href="15768353446694.html">TensorFlow Sparse的一个优化</a></li>
          
            <li><a title="基础知识背景" href="15768070172080.html">基础知识背景</a></li>
          
            <li><a title="TensorFlow优化" href="15744799610685.html">TensorFlow优化</a></li>
          
            <li><a title="GDG上海 2019.10.13分享内容准备" href="15673444950441.html">GDG上海 2019.10.13分享内容准备</a></li>
          
            <li><a title="Dive Into TensorFlow" href="15659603996762.html">Dive Into TensorFlow</a></li>
          
            <li><a title="Maybe Best Practice With Sparse Machine Learning In TensorFlow" href="15430699092916.html">Maybe Best Practice With Sparse Machine Learning In TensorFlow</a></li>
          

      
        <li class="divider"></li>
        <li><label>机器学习平台</label></li>

          
            <li><a title="---" href="16533711069508.html">---</a></li>
          
            <li><a title="机器学习平台在云音乐的持续实践" href="16371350579612.html">机器学习平台在云音乐的持续实践</a></li>
          
            <li><a title="泛模型管理与分发" href="16076083666793.html">泛模型管理与分发</a></li>
          
            <li><a title="机器学习与容器化平台" href="15861773530303.html">机器学习与容器化平台</a></li>
          
            <li><a title="机器学习工程实践" href="15648106167930.html">机器学习工程实践</a></li>
          

      
        <li class="divider"></li>
        <li><label>图计算</label></li>

          
            <li><a title="直播场景PGL落地" href="16078481811620.html">直播场景PGL落地</a></li>
          
            <li><a title="Graph Neural Networks" href="16077533959046.html">Graph Neural Networks</a></li>
          
            <li><a title="graph representation learning" href="16077533959085.html">graph representation learning</a></li>
          
            <li><a title="Spectral Clustering" href="16029890553575.html">Spectral Clustering</a></li>
          
            <li><a title="Community structure in networks" href="16019601035128.html">Community structure in networks</a></li>
          
            <li><a title="Motifs and structural roles in networks" href="16017096445579.html">Motifs and structural roles in networks</a></li>
          
            <li><a title="Properties of Networks and Random Graph Model" href="16016274752497.html">Properties of Networks and Random Graph Model</a></li>
          

      
        <li class="divider"></li>
        <li><label>pytorch</label></li>

          
            <li><a title="pytorch 环境安装及配置" href="15808187045354.html">pytorch 环境安装及配置</a></li>
          

      
        <li class="divider"></li>
        <li><label>分布式系统</label></li>

          
            <li><a title="分布式一致性" href="15860748439491.html">分布式一致性</a></li>
          
            <li><a title="raft 参考文章" href="15854050053037.html">raft 参考文章</a></li>
          
            <li><a title="分布式系统书籍" href="15853877486542.html">分布式系统书籍</a></li>
          
            <li><a title="容灾【备份】" href="15848127872361.html">容灾【备份】</a></li>
          
            <li><a title="容灾【备份】" href="15848127093419.html">容灾【备份】</a></li>
          

      
        <li class="divider"></li>
        <li><label>mlops</label></li>

          
            <li><a title="模型生产环境中的反馈与数据回流" href="16490569390259.html">模型生产环境中的反馈与数据回流</a></li>
          
            <li><a title="mlops之监控与数据回流" href="16482627913984.html">mlops之监控与数据回流</a></li>
          
            <li><a title="为机器学习量身定做的ops工具：cml & dvc" href="16268581441013.html">为机器学习量身定做的ops工具：cml & dvc</a></li>
          
            <li><a title="[toc]" href="16003962131575.html">[toc]</a></li>
          

      
        <li class="divider"></li>
        <li><label>paddle</label></li>

          
            <li><a title="直播场景PGL落地" href="16078655202819.html">直播场景PGL落地</a></li>
          

      
        <li class="divider"></li>
        <li><label>参数服务器</label></li>

          
            <li><a title="ps-lite" href="15836784836219.html">ps-lite</a></li>
          
            <li><a title="ps-lite再一次研读源码" href="15536014868367.html">ps-lite再一次研读源码</a></li>
          

      
        <li class="divider"></li>
        <li><label>GAN</label></li>

          
            <li><a title="深度解析为什么GAN能是Structured Learning的一种解决方案" href="Introduction%20to%20GAN.html">深度解析为什么GAN能是Structured Learning的一种解决方案</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>推荐系统</span></li>
                        
                          <li><a title="推荐系统的禅与道" href="15951226773958.html">推荐系统的禅与道</a></li>
                        
                          <li><a title="推荐系统灌水文之如何理解Item" href="15763400595374.html">推荐系统灌水文之如何理解Item</a></li>
                        

                    
                      <li class="side-title"><span>TensorFlow</span></li>
                        
                          <li><a title="TensorFlow Sparse的一个优化" href="15768353446694.html">TensorFlow Sparse的一个优化</a></li>
                        
                          <li><a title="基础知识背景" href="15768070172080.html">基础知识背景</a></li>
                        
                          <li><a title="TensorFlow优化" href="15744799610685.html">TensorFlow优化</a></li>
                        
                          <li><a title="GDG上海 2019.10.13分享内容准备" href="15673444950441.html">GDG上海 2019.10.13分享内容准备</a></li>
                        
                          <li><a title="Dive Into TensorFlow" href="15659603996762.html">Dive Into TensorFlow</a></li>
                        
                          <li><a title="Maybe Best Practice With Sparse Machine Learning In TensorFlow" href="15430699092916.html">Maybe Best Practice With Sparse Machine Learning In TensorFlow</a></li>
                        

                    
                      <li class="side-title"><span>机器学习平台</span></li>
                        
                          <li><a title="---" href="16533711069508.html">---</a></li>
                        
                          <li><a title="机器学习平台在云音乐的持续实践" href="16371350579612.html">机器学习平台在云音乐的持续实践</a></li>
                        
                          <li><a title="泛模型管理与分发" href="16076083666793.html">泛模型管理与分发</a></li>
                        
                          <li><a title="机器学习与容器化平台" href="15861773530303.html">机器学习与容器化平台</a></li>
                        
                          <li><a title="机器学习工程实践" href="15648106167930.html">机器学习工程实践</a></li>
                        

                    
                      <li class="side-title"><span>图计算</span></li>
                        
                          <li><a title="直播场景PGL落地" href="16078481811620.html">直播场景PGL落地</a></li>
                        
                          <li><a title="Graph Neural Networks" href="16077533959046.html">Graph Neural Networks</a></li>
                        
                          <li><a title="graph representation learning" href="16077533959085.html">graph representation learning</a></li>
                        
                          <li><a title="Spectral Clustering" href="16029890553575.html">Spectral Clustering</a></li>
                        
                          <li><a title="Community structure in networks" href="16019601035128.html">Community structure in networks</a></li>
                        
                          <li><a title="Motifs and structural roles in networks" href="16017096445579.html">Motifs and structural roles in networks</a></li>
                        
                          <li><a title="Properties of Networks and Random Graph Model" href="16016274752497.html">Properties of Networks and Random Graph Model</a></li>
                        

                    
                      <li class="side-title"><span>pytorch</span></li>
                        
                          <li><a title="pytorch 环境安装及配置" href="15808187045354.html">pytorch 环境安装及配置</a></li>
                        

                    
                      <li class="side-title"><span>分布式系统</span></li>
                        
                          <li><a title="分布式一致性" href="15860748439491.html">分布式一致性</a></li>
                        
                          <li><a title="raft 参考文章" href="15854050053037.html">raft 参考文章</a></li>
                        
                          <li><a title="分布式系统书籍" href="15853877486542.html">分布式系统书籍</a></li>
                        
                          <li><a title="容灾【备份】" href="15848127872361.html">容灾【备份】</a></li>
                        
                          <li><a title="容灾【备份】" href="15848127093419.html">容灾【备份】</a></li>
                        

                    
                      <li class="side-title"><span>mlops</span></li>
                        
                          <li><a title="模型生产环境中的反馈与数据回流" href="16490569390259.html">模型生产环境中的反馈与数据回流</a></li>
                        
                          <li><a title="mlops之监控与数据回流" href="16482627913984.html">mlops之监控与数据回流</a></li>
                        
                          <li><a title="为机器学习量身定做的ops工具：cml & dvc" href="16268581441013.html">为机器学习量身定做的ops工具：cml & dvc</a></li>
                        
                          <li><a title="[toc]" href="16003962131575.html">[toc]</a></li>
                        

                    
                      <li class="side-title"><span>paddle</span></li>
                        
                          <li><a title="直播场景PGL落地" href="16078655202819.html">直播场景PGL落地</a></li>
                        

                    
                      <li class="side-title"><span>参数服务器</span></li>
                        
                          <li><a title="ps-lite" href="15836784836219.html">ps-lite</a></li>
                        
                          <li><a title="ps-lite再一次研读源码" href="15536014868367.html">ps-lite再一次研读源码</a></li>
                        

                    
                      <li class="side-title"><span>GAN</span></li>
                        
                          <li><a title="深度解析为什么GAN能是Structured Learning的一种解决方案" href="Introduction%20to%20GAN.html">深度解析为什么GAN能是Structured Learning的一种解决方案</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">

 <div class="markdown-body">
<h1>Maybe Best Practice With Sparse Machine Learning In TensorFlow</h1>

<h2><a id="tensorflow%E7%8E%B0%E7%8A%B6%E5%8F%8A%E8%83%8C%E6%99%AF" class="anchor" aria-hidden="true" href="#tensorflow%E7%8E%B0%E7%8A%B6%E5%8F%8A%E8%83%8C%E6%99%AF"><span class="octicon octicon-link"></span></a>TensorFlow现状及背景</h2>
<p>在机器学习这块，Estimator本身的封装能够适应比较多的Dense的场景，而对于Sparse的场景无论是官方demo还是一些业界的大牛都分享的比较少，在很多场景，比如libfm、libffm、Xgboost都支持直接libsvm, field-libsvm的格式中读入数据，训练模型没有原始的实现，没法直接调包使用，得自己在TensorFlow的框架上构造，所幸Estimator本身的框架支持自定义的input_fn，和自定义的model_fn，笔者过去一段时间工作之余研究了下，并实现了基于libsvm的Sparse Logistic Regression和Sparse Factorization Machine， 打通了从数据读取、模型训练、到TensorFlow Serving的部署。</p>
<h2><a id="tensorflow%E4%B8%AD%E7%9A%84sparse-tensor%E5%AE%9E%E7%8E%B0" class="anchor" aria-hidden="true" href="#tensorflow%E4%B8%AD%E7%9A%84sparse-tensor%E5%AE%9E%E7%8E%B0"><span class="octicon octicon-link"></span></a>TensorFlow中的sparse_tensor实现</h2>
<p>我们读下sparse_tensor的源码，<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/sparse_tensor.py">sparse_tensor.py</a>, 很容易看出来sparse_tensor在TensorFlow中是一个高层的封装，主要包括indices, values, shape三个部分，这里很有意思，后面我实践中遇到一个大坑，可以通过这里解决，这里我先卖个关子；</p>
<h3><a id="sparse-representation%E7%9A%84%E5%A5%BD%E5%A4%84" class="anchor" aria-hidden="true" href="#sparse-representation%E7%9A%84%E5%A5%BD%E5%A4%84"><span class="octicon octicon-link"></span></a>sparse representation的好处</h3>
<p>常见的稀疏矩阵的表示有csc，csr，在很多矩阵计算的库当中有使用，比如python中大家使用比较多的scipy，TensorFlow底层计算模块eigen，都是用类似的方式来表示稀疏矩阵，举个例子比如某个商户有500万个商品，而用户产生行为的商品必定远远小于500万，如果都是用dense表示，那么保存单个用户行为的商品数据需要500万个指，而采用稀疏数据表示则保存所需要的空间只需要和你才产生行为的商品数量有关，如下图100个用户的在500w上的行为数据如果用dense表示需要大概3G的空间；<br />
<img src="media/15430699092916/15430700826674.jpg" alt="" /><br />
需要保存100*5000000个int，而使用csc_matrix，</p>
<pre><code>row = np.array(range(100))
col = np.zeros(100)
data = np.ones(100)
csc_matrix((data, (row, col)), shape=(100, 5000000))
</code></pre>
<p>我们只需要保存3*NNZ（这里就是100）个int，然后加上一个shape信息，空间占用大大减少；<br />
在内存中，我们通常使用csc来表示Sparse Matrix，而在样本保存中，通常使用libsvm格式来保存</p>
<pre><code>1 1:1 2:1 3:1 4:1 5:1 6:1 7:1 8:0.301 9:0.602 10:1 11:1 12:1 13:1 14:1 15:1 16:1 17:1 18:1 19:1 20:1 21:1 22:1
</code></pre>
<p>以空格为sep，label为1， 后续为feature的表示，格式为feature_id: feature_val, 在TensorFlow中我们可以使用TextlineDataset自定义input_fn来解析文本，其他很多相关的技术文章都有提及，但是作为一个程序员总感觉不想走已经走过的路，而且TF官宣tfrecord的读写效率高， 考虑到效率问题，我这里使用TFRecordDataset来做数据的读取；</p>
<h3><a id="libsvm-to-tfrecord" class="anchor" aria-hidden="true" href="#libsvm-to-tfrecord"><span class="octicon octicon-link"></span></a>LibSVM To TFRecord</h3>
<p>解析LibSVM feature_ids, 和feature_vals， 很简单没有啥好说的， 直接贴代码，想要深入了解的，可以去看看TF的<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto">example.proto</a>, <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto">feature.proto</a>, 就大概能了解Example和Feature的逻辑了，不用闷闷地只知道别人是这样写的。</p>
<pre><code>import codecs
import tensorflow as tf
import logging


logger = logging.getLogger(&quot;TFRecSYS&quot;)
sh = logging.StreamHandler(stream=None)
logger.setLevel(logging.DEBUG)
fmt = &quot;%(asctime)-15s %(levelname)s %(filename)s %(lineno)d %(process)d %(message)s&quot;
datefmt = &quot;%a %d %b %Y %H:%M:%S&quot;
formatter = logging.Formatter(fmt, datefmt)
sh.setFormatter(formatter)
logger.addHandler(sh)

class LibSVM2TFRecord(object):
    def __init__(self, libsvm_filenames, tfrecord_filename, info_interval=10000, tfrecord_large_line_num = 10000000):
        self.libsvm_filenames = libsvm_filenames
        self.tfrecord_filename = tfrecord_filename
        self.info_interval = info_interval
        self.tfrecord_large_line_num = tfrecord_large_line_num

    def set_transform_files(self, libsvm_filenames, tfrecord_filename):
        self.libsvm_filenames = libsvm_filenames
        self.tfrecord_filename = tfrecord_filename

    def fit(self):
        logger.info(self.libsvm_filenames)
        writer = tf.python_io.TFRecordWriter(self.tfrecord_filename+&quot;.tfrecord&quot;)
        tfrecord_num = 1
        for libsvm_filename in self.libsvm_filenames:
            logger.info(&quot;Begin to process {0}&quot;.format(libsvm_filename))
            with codecs.open(libsvm_filename, mode='r', encoding='utf-8') as fread:
                line = fread.readline()
                line_num = 0
                while line:
                    line = fread.readline()
                    line_num += 1
                    if line_num % self.info_interval == 0:
                        logger.info(&quot;Processing the {0} line sample&quot;.format(line_num))
                    if line_num % self.tfrecord_large_line_num == 0:
                        writer.close()
                        tfrecord_file_component = self.tfrecord_filename.split(&quot;.&quot;)
                        self.tfrecord_filename = self.tfrecord_filename.split(&quot;_&quot;)[0]+&quot;_%05d.tfrecord&quot;%tfrecord_num
                        writer = tf.python_io.TFRecordWriter(self.tfrecord_filename)
                        tfrecord_num += 1
                        logger.info(&quot;Change the tfrecord file to {0}&quot;.format(self.tfrecord_filename))
                    feature_ids = []
                    vals = []
                    line_components = line.strip().split(&quot; &quot;)
                    try:
                        # label = 1.0 if line_components[0] == &quot;+1&quot; else 0.0
                        label = float(line_components[0])
                        features = line_components[1:]
                    except IndexError:
                        logger.info(&quot;Index Error, line: {0}&quot;.format(line))
                        continue
                    for feature in features:
                        feature_components = feature.split(&quot;:&quot;)
                        try:
                            feature_id = int(feature_components[0])
                            val = float(feature_components[1])                        
                        except IndexError:
                            logger.info(&quot;Index Error: , feature_components: {0}&quot;,format(feature))
                            continue
                        except ValueError:
                            logger.info(&quot;Value Error: feature_components[0]: {0}&quot;.format(feature_components[0]) )
                        feature_ids.append(feature_id)
                        vals.append(val)
                    tfrecord_feature = {
                        &quot;label&quot; : tf.train.Feature(float_list=tf.train.FloatList(value=[label])),
                        &quot;feature_ids&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=feature_ids)),
                        &quot;feature_vals&quot;: tf.train.Feature(float_list=tf.train.FloatList(value=vals))
                    }
                    example = tf.train.Example(features=tf.train.Features(feature=tfrecord_feature))
                    writer.write(example.SerializeToString())
                writer.close()
            logger.info(&quot;libsvm: {0} transform to tfrecord: {1} successfully&quot;.format(libsvm_filename, self.tfrecord_filename))

if __name__ == &quot;__main__&quot;:
    libsvm_to_tfrecord = LibSVM2TFRecord([&quot;../../data/kdd2010/kdda.libsvm&quot;], &quot;../../data/kdd2010/kdda&quot;)
    libsvm_to_tfrecord.fit()
</code></pre>
<p><img src="media/15430699092916/15430710947264.jpg" alt="" /></p>
<p>转成tfrecord文件之后，通常比原始的文件要大一些，具体的格式的说明参考下<a href="https://cloud.tencent.com/developer/article/1088751">https://cloud.tencent.com/developer/article/1088751</a> 这篇文章比较详细地介绍了转tfrecord和解析tfrecord的用法，另外关于shuffle的buff size的问题，个人感觉问题并不大，在推荐场景下，数据条数多，其实内存消耗也不大，只是在运行前会有比较长载入解析的时间，另外一个问题是，大家应该都会提问的，为啥tfrecord会比自己写input_fn去接下文本文件最后来的快呢？<br />
这里我只能浅层意义上去猜测，这部分代码没有拎出来读过，所以不做回复哈，有读过源码，了解比较深的同学可以解释下</p>
<h3><a id="tfrecord%E7%9A%84%E8%A7%A3%E6%9E%90" class="anchor" aria-hidden="true" href="#tfrecord%E7%9A%84%E8%A7%A3%E6%9E%90"><span class="octicon octicon-link"></span></a>TFRecord的解析</h3>
<pre><code>import tensorflow as tf

class LibSVMInputReader(object):
    def __init__(self, file_queue, batch_size, capacity, min_after_dequeue):
        self.file_queue = file_queue
        self.batch_size = batch_size
        self.capacity = capacity
        self.min_after_dequeue = min_after_dequeue

def read(self):
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(self.file_queue)
    shuffle_batch_example = tf.train.shuffle_batch([serialized_example], 
                            batch_size=self.batch_size, capacity=self.capacity,
                            min_after_dequeue=self.min_after_dequeue)
    features = tf.parse_example(shuffle_batch_example, features={
                    &quot;label&quot; : tf.FixedLenFeature([], tf.float32),
                    &quot;feature_ids&quot;: tf.VarLenFeature(tf.int64),
                    &quot;feature_vals&quot;: tf.VarLenFeature(tf.float32)
                })
    batch_label = features['label']
    batch_feature_ids = features['feature_ids']
    batch_feature_vals = features['feature_vals']
    return batch_label, batch_feature_ids, batch_feature_vals
</code></pre>
<p>个人读了一些解析tfrecord的几个格式的源码，现在还有点乱，大概现在貌似代码中有支持VarLenFeature, SparseFeature, FixedLenFeature, FixedLenSequenceFeature这几种，但是几个api的说明里面貌似对sparsefeature的支持有点磨砺两可，所以选择使用VarLenFeature上面的方式， 不知道这里SparseFeature是怎么玩的，有时间还得仔细看看。</p>
<p>然后，简单写个读取的demo：</p>
<pre><code>import tensorflow as tf
from libsvm_input_reader import LibSVMInputReader
from sparse2train import Sparse2Train

filename_queue = tf.train.string_input_producer([&quot;../../data/kdd2010/kdda_t.tfrecord&quot;], num_epochs=1, shuffle=True)
lib_svm_input_reader = LibSVMInputReader(filename_queue, 2, 1000, 200)

init_op = tf.group(tf.initialize_all_variables(),tf.initialize_local_variables())
batch_label, batch_feature_ids, batch_feature_vals = lib_svm_input_reader.read()
with tf.Session() as sess:
    sess.run(init_op)
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)
    try:
        step = 0
        while not coord.should_stop():
            step += 1
            print &quot;step: {0}&quot;.format(step)
            batch_label_list, batch_feature_ids_list, batch_feature_vals_list = sess.run([batch_label, batch_feature_ids, batch_feature_vals])
            print(batch_feature_ids_list)
            # sparse_2_train_obj = Sparse2Train(batch_label_list, batch_feature_ids_list, batch_feature_vals_list)
            # batch_label_array, batch_feature_ids_array, batch_feature_vals_array = sparse_2_train_obj.fit()
            # print batch_feature_ids_array
            # print batch_feature_vals_array
    except tf.errors.OutOfRangeError:
        print &quot;Done Training&quot;
    finally:
        coord.request_stop()
        coord.join(threads)
</code></pre>
<p>大家可以动手跑跑看，仔细研究的话会发现一些比较有意思的东西，比如VarLenFeature出来的是一个SparseTensor，<img src="media/15430699092916/15430745826244.jpg" alt="" /><br />
这里我最开始是打算每次sess.run，然后转换为numpy.array, 然后再喂feed_dict到模型，但是觉得这样会很麻烦，速度会是瓶颈，如果能过直接使用这里的SparseTensor去做模型的计算，直接从tfrecord解析，应该会比较好，但是又会遇到另一个问题，后面再详细说明；这里简单提下，我这边就是直接拿到两个SparseTensor，直接去到模型，所以模型的设计会和常规的算法会有不同；</p>
<h3><a id="sparse-model%E7%9A%84%E9%AB%98%E6%95%88%E5%AE%9E%E7%8E%B0" class="anchor" aria-hidden="true" href="#sparse-model%E7%9A%84%E9%AB%98%E6%95%88%E5%AE%9E%E7%8E%B0"><span class="octicon octicon-link"></span></a>Sparse Model的高效实现</h3>
<pre><code>import tensorflow as tf

class SparseFactorizationMachine(object):
    def __init__(self, model_name=&quot;sparse_fm&quot;):
        self.model_name = model_name

    def build(self, features, labels, mode, params):
        print(&quot;export features {0}&quot;.format(features))
        print(mode)
        if mode == tf.estimator.ModeKeys.PREDICT:
            sp_indexes = tf.SparseTensor(indices=features['DeserializeSparse:0'],
                         values=features['DeserializeSparse:1'],
                         dense_shape=features['DeserializeSparse:2'])
            sp_vals = tf.SparseTensor(indices=features['DeserializeSparse_1:0'],
                                      values=features['DeserializeSparse_1:1'],
                                      dense_shape=features['DeserializeSparse_1:2'])
        if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:
            sp_indexes = features['feature_ids']
            sp_vals = features['feature_vals']
            print(&quot;sp: {0}, {1}&quot;.format(sp_indexes, sp_vals))
        batch_size = params[&quot;batch_size&quot;]
        feature_max_num = params[&quot;feature_max_num&quot;]
        optimizer_type = params[&quot;optimizer_type&quot;]
        factor_vec_size = params[&quot;factor_size&quot;]

        # first part
        bias = tf.get_variable(name=&quot;b&quot;, shape=[1], initializer=tf.glorot_normal_initializer())
        w_first_order = tf.get_variable(name='w_first_order', shape=[feature_max_num, 1], initializer=tf.glorot_normal_initializer())
        linear_part = tf.nn.embedding_lookup_sparse(w_first_order, sp_indexes, sp_vals, combiner=&quot;sum&quot;) + bias
        # second part
        w_second_order = tf.get_variable(name='w_second_order', shape=[feature_max_num, factor_vec_size], initializer=tf.glorot_normal_initializer())

        embedding = tf.nn.embedding_lookup_sparse(w_second_order, sp_indexes, sp_vals, combiner=&quot;sum&quot;)
        embedding_square = tf.nn.embedding_lookup_sparse(tf.square(w_second_order), sp_indexes, tf.square(sp_vals), combiner=&quot;sum&quot;)
        sum_square = tf.square(embedding)
        # square_sum = 
        second_part = 0.5*tf.reduce_sum(tf.subtract(sum_square, embedding_square), 1)
        y_hat = linear_part + tf.expand_dims(second_part, -1)
        # y_hat = linear_part
        predictions = tf.sigmoid(y_hat)
        print &quot;y_hat: {0}, second_part: {1}, linear_part: {2}&quot;.format(y_hat, second_part, linear_part)
        pred = {&quot;prob&quot;: predictions}
        export_outputs = {
            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: tf.estimator.export.PredictOutput(predictions)
        }
        if mode == tf.estimator.ModeKeys.PREDICT:
            return tf.estimator.EstimatorSpec(
                mode=mode, 
                predictions=predictions,
                export_outputs=export_outputs)
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=tf.squeeze(y_hat)))
        if optimizer_type == &quot;sgd&quot;:
            opt = tf.train.GradientDescentOptimizer(learning_rate=params['learning_rate'])
        elif optimizer_type == &quot;ftrl&quot;:
            opt = tf.train.FtrlOptimizer(learning_rate=params['learning_rate'],)
        elif optimizer_type == &quot;adam&quot;:
            opt = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])
        elif optimizer_type == &quot;momentum&quot;:
            opt = tf.train.MomentumOptimizer(learning_rate=params['learning_rate'], momentum=params['momentum'])
        train_step = opt.minimize(loss,global_step=tf.train.get_global_step())
        eval_metric_ops = {
            &quot;auc&quot; : tf.metrics.auc(labels, predictions)
        }

        if mode == tf.estimator.ModeKeys.TRAIN:
            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_step)
        if mode == tf.estimator.ModeKeys.EVAL:
            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, eval_metric_ops=eval_metric_ops)
</code></pre>
<p>这里讲个Factorization Machine的实现，会比Sparse Logistic Regression的实现要稍微复杂一点，首先，模型的算法实现，比较简单，随便搜下应该大概都知道Factorization Machine的算法原理，fm主要包括两个部分，一个是LogisticRegression的部分，包括bias和一阶特征，另外一部分是把每一维特征表示为一个指定大小的vector，去从样本中去学习对训练有效的交叉信息：</p>
<pre><code>bias = tf.get_variable(name=&quot;b&quot;, shape=[1], initializer=tf.glorot_normal_initializer())
w_first_order = tf.get_variable(name='w_first_order', shape=[feature_max_num, 1], initializer=tf.glorot_normal_initializer())
linear_part = tf.nn.embedding_lookup_sparse(w_first_order, sp_indexes, sp_vals, combiner=&quot;sum&quot;) + bias
# second part
w_second_order = tf.get_variable(name='w_second_order', shape=[feature_max_num, factor_vec_size], initializer=tf.glorot_normal_initializer())

embedding = tf.nn.embedding_lookup_sparse(w_second_order, sp_indexes, sp_vals, combiner=&quot;sum&quot;)
embedding_square = tf.nn.embedding_lookup_sparse(tf.square(w_second_order), sp_indexes, tf.square(sp_vals), combiner=&quot;sum&quot;)
sum_square = tf.square(embedding)
# square_sum = 
second_part = 0.5*tf.reduce_sum(tf.subtract(sum_square, embedding_square), 1)
y_hat = linear_part + tf.expand_dims(second_part, -1)
# y_hat = linear_part
predictions = tf.sigmoid(y_hat)
</code></pre>
<p>这里和普通的fm唯一不同的是，我使用tf.nn.embedding_lookup_sparse 来计算WX，在海量特征维度的前提下，做全部的WX相乘是耗时，且没有必要的，我们只需要取出其中有值的部分来计算即可，比如kdd2010，两千万维的特征，但是计算WX其实就会考验系统的瓶颈，但是如果经过一个简单的tf.nn.embedding_lookup_sparse来替代WX，就会先lookup feature_id，对应的embedding的表示，然后乘以相应的weight，最后在每一个样本上进行一个combiner(sum)的操作，其实就是等同于WX，<code>tf.nn.embedding_lookup_sparse(w_first_order, sp_indexes, sp_vals, combiner=&quot;sum&quot;)</code>, 而在系统方面，由于计算只与NNZ(非零数)有关， 性能则完全没有任何压力。二阶的部分可以降低时间复杂度，相信应该了解FM的都知道，和的平方减去平方的和：</p>
<pre><code>embedding_square = tf.nn.embedding_lookup_sparse(tf.square(w_second_order), sp_indexes, tf.square(sp_vals), combiner=&quot;sum&quot;)
sum_square = tf.square(embedding)
# square_sum = 
second_part = 0.5*tf.reduce_sum(tf.subtract(sum_square, embedding_square), 1)
</code></pre>
<p>由上面的实现，我们只需要把特征的sp_indexes, sp_val传出来就可以了， 但是因为这两者都是SparseTensor，笔者开始想到的不是上述的实现，而是使用<code>tf.sparse.placeholder</code>， 然后喂一个feed_dict，对应SparseTensorValue就可以了，确实是可以的，模型训练没有问题，模型export出来也没有问题(其实是有问题的， 我这里重写了Estimator的<code>build_raw_serving_input_receiver_fn</code>使其支持SparseTensor)，但是在部署好TensorFlow Serving之后，我发现在客户端SparseTensorValue貌似不能组成一个TensorProto，<code>tf.make_tensor_proto</code>主要是把请求的值放进一个TensorProto，而TensorProto, <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor.proto">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor.proto</a>，貌似不能直接支持SparseTensorValue去放进TensorProto，所以就无法在部署好TensorFlow Serving后去请求（部署会在后文详细描述，这里我也想过能不能改他们的代码，但是貌似涉及太底层的东西，有点hold不住），但是也是有办法的，前面文章提到SparseTensor，在TensorFlow中是高阶的api，他其实就是由3个Tensor组成，是否可以把SparseTensor本身的3个Tensor暴露出来，然后请求的时候去组这三个Tensor就可以啦，所以只需要找到TFRecord接下出来的sp_indexes, sp_vals就可以了<br />
<img src="media/15430699092916/15431157444207.jpg" alt="" /><br />
从这里很容易看到sp_indexes, sp_vals的TensorName，然后用占位符替代，然后用这些去组成sp_indexes，sp_vals</p>
<p><img src="media/15430699092916/15431159725571.jpg" alt="" /><br />
<img src="media/15430699092916/15431160229213.jpg" alt="" /><br />
说明下，这里我使用的kdd2010的数据，特征维度是20216831，样本数量8407752,我是用我15年的macbook pro跑的， 使用的sgd， 收敛还是比较明显的， 大家有兴趣可以试试，按以往经验使用其他优化器如adam，ftrl会在这种特征规模比较大的条件下有比较好的提升，我这里就走通整个流程，另外机器也不忍心折腾；<br />
到了这里，就训练出来了一个可用的Sparse FM的模型，接下来要导出模型，这里的导出模型是导出一个暴露了placeholder的模型，可以在TensorFlow Serving被载入，被请求，不是单纯的ckpt；</p>
<h3><a id="%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2" class="anchor" aria-hidden="true" href="#%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2"><span class="octicon octicon-link"></span></a>模型部署</h3>
<pre><code>feature_spec = {
            'DeserializeSparse:0': tf.placeholder(dtype=tf.int64, name='feature_ids/indices'),
            'DeserializeSparse:1': tf.placeholder(dtype=tf.int64, name='feature_ids/values'),
            'DeserializeSparse:2': tf.placeholder(dtype=tf.int64, name='feaurte_ids/shape'),
            'DeserializeSparse_1:0': tf.placeholder(dtype=tf.int64, name='feature_vals/indices'),
            'DeserializeSparse_1:1': tf.placeholder(dtype=tf.float32, name='feature_vals/values'),
            'DeserializeSparse_1:2': tf.placeholder(dtype=tf.int64, name='feature_vals/shape')
        }
serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec, is_sparse=False)
sparse_fm_model.export_savedmodel(servable_model_dir, serving_input_receiver_fn, as_text=True)
</code></pre>
<p>和前面构造模型的时候对应，只需要把DeserializeSparse的部分暴露出来即可<br />
<img src="media/15430699092916/15431172755613.jpg" alt="" /></p>
<p>这里会以时间戳创建模型，保存成功后temp-1543117151会变为1543117151，接下来，就是要启动TensorFlow Serving载入模型：<code>docker run -p 8500:8500 --mount type=bind,source=/Users/burness/work/tencent/TFRecSYS/TFRecSYS/runner/save_model,target=/models/ -e MODEL_NAME=sparse_fm -t tensorflow/serving</code>，使用官方提供的docker镜像来部署环境很方便。<br />
<img src="media/15430699092916/15431177337381.jpg" alt="" /><br />
会先载入新的模型，然后unload旧模型，从命令行log信息可以看出gRPC接口为8500<br />
剩下的，就下一个client，去请求</p>
<pre><code>import grpc
import sys
sys.path.insert(0, &quot;./&quot;)
from tensorflow_serving.apis import predict_pb2
from tensorflow_serving.apis import prediction_service_pb2_grpc
# from grpc.beta import implementations
import tensorflow as tf
from tensorflow.python.framework import dtypes
import time
import numpy as np
from sklearn import metrics

def get_sp_component(file_name):
    with open(file_name, &quot;r&quot;) as fread:
        for line in fread.readlines():
            fea_ids = []
            fea_vals = []
            line_components = line.strip().split(&quot; &quot;)
            label = float(line_components[0])
            for part in line_components[1:]:
                part_components = part.split(&quot;:&quot;)
                fea_ids.append(int(part_components[0]))
                fea_vals.append(float(part_components[1]))
            yield (label, fea_ids, fea_vals)

def batch2sparse_component(fea_ids, fea_vals):
    feature_id_indices = []
    feature_id_values = []
    feature_vals_indices = []
    feature_vals_values = []
    for index, id in enumerate(fea_ids):
        feature_id_values += id
        for i in range(len(id)):
            feature_id_indices.append([index, i])
    for index, val in enumerate(fea_vals):
        feature_vals_values +=val
        for i in range(len(val)):
            feature_vals_indices.append([index, i])
    return np.array(feature_id_indices, dtype=np.int64), np.array(feature_id_values, dtype=np.int64), np.array(feature_vals_indices, dtype=np.int64), np.array(feature_vals_values, dtype=np.float32)    



if __name__ == '__main__':
    start_time = time.time()
    channel = grpc.insecure_channel(&quot;127.0.0.1:8500&quot;)
    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)
    request = predict_pb2.PredictRequest()
    request.model_spec.name = &quot;sparse_fm&quot;
    record_genertor = get_sp_component(&quot;../../data/kdd2010/kdda_t.libsvm&quot;)
    batch_size = 1000
    
    predictions = np.array([])
    labels = []
    while True:
        try:
            batch_label = []
            batch_fea_ids = []
            batch_fea_vals = []
            max_fea_size = 0
            for i in range(batch_size):
                label, fea_ids, fea_vals = next(record_genertor)
                # print label, fea_ids, fea_vals
                batch_label.append(label)
                batch_fea_ids.append(fea_ids)
                batch_fea_vals.append(fea_vals)
                if len(batch_fea_ids) &gt; max_fea_size:
                    max_fea_size = len(batch_fea_ids)
            shape = np.array([batch_size, max_fea_size],dtype=np.int64 )
            batch_feature_id_indices, batch_feature_id_values,batch_feature_val_indices, batch_feature_val_values  = batch2sparse_component(batch_fea_ids, batch_fea_vals)
            # print(batch_feature_val_indices)
            request.inputs[&quot;DeserializeSparse:0&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(batch_feature_id_indices))
            request.inputs[&quot;DeserializeSparse:1&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(batch_feature_id_values))
            request.inputs[&quot;DeserializeSparse:2&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(shape))
            request.inputs[&quot;DeserializeSparse_1:0&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(batch_feature_val_indices))
            request.inputs[&quot;DeserializeSparse_1:1&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(batch_feature_val_values))
            request.inputs[&quot;DeserializeSparse_1:2&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(shape))
            response = stub.Predict(request, 10.0)
            results = {}
            for key in response.outputs:
                tensor_proto = response.outputs[key]
                nd_array = tf.contrib.util.make_ndarray(tensor_proto)
                results[key] = nd_array
            print(&quot;cost %ss to predict: &quot; % (time.time() - start_time))
            # print(results[&quot;prob&quot;])
            # print results
            
            predictions = np.append(predictions, results['output'])
            labels += batch_label
            # print(predictions)
            print(len(labels), len(predictions))

        except StopIteration:
            break
    fpr, tpr, thresholds = metrics.roc_curve(labels, predictions)
    print(&quot;auc: {0}&quot;,format(metrics.auc(fpr, tpr)))
    # 1:1 2:1 3:1 4:1 5:1 6:1 7:1 8:0.301 9:0.602 10:1 11:1 12:1 13:1 14:1 15:1 16:1 17:1 18:1 19:1 20:1 21:1 22:1
    # id_indices = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],[0,6],[0,7],[0,8],[0,9],[0,10],[0,11],[0,12],[0,13],[0,14],[0,15],[0,16],[0,17],[0,18],[0,19],[0,20],[0,21]], dtype=np.int64)
    # id_values = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], dtype=np.int64)
    # id_shape = np.array([1,22], dtype=np.int64)
    # val_indices = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],[0,6],[0,7],[0,8],[0,9],[0,10],[0,11],[0,12],[0,13],[0,14],[0,15],[0,16],[0,17],[0,18],[0,19],[0,20],[0,21]], dtype=np.int64)
    # val_values = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.301, 0.602, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], dtype=np.float32)
    # val_shape = np.array([1,22], dtype=np.int64)

    # request.inputs[&quot;DeserializeSparse:0&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(id_indices))
    # request.inputs[&quot;DeserializeSparse:1&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(id_values))
    # request.inputs[&quot;DeserializeSparse:2&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(id_shape))
    # request.inputs[&quot;DeserializeSparse_1:0&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(val_indices))
    # request.inputs[&quot;DeserializeSparse_1:1&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(val_values))
    # request.inputs[&quot;DeserializeSparse_1:2&quot;].CopyFrom(tf.contrib.util.make_tensor_proto(val_shape))

    # response = stub.Predict(request, 10.0)
    # results = {}
    # for key in response.outputs:
    #     tensor_proto = response.outputs[key]
    #     nd_array = tf.contrib.util.make_ndarray(tensor_proto)
    #     results[key] = nd_array
    # print(&quot;cost %ss to predict: &quot; % (time.time() - start_time))
    # # print(results[&quot;pro&quot;])
    # print(results[&quot;output&quot;])
</code></pre>
<p>开始用一个样本做测试打出pred的值，成功后，我将所有的测试样本去组batch去请求，然后计算下auc，对比下eval的时候的auc,差不多，那说明整体流程没啥问题，另外每1000个样本耗时大概270多ms，整体感觉还可以。<br />
<img src="media/15430699092916/15431184236033.jpg" alt="" /></p>
<h3><a id="%E5%90%8E%E7%BB%AD" class="anchor" aria-hidden="true" href="#%E5%90%8E%E7%BB%AD"><span class="octicon octicon-link"></span></a>后续</h3>
<p>基本到这里就差不多了，现在已经支持单个field的Logistic Regression和Factorization Machine，扩展性比较强，只需要重写算法的类，剩余的大部分都可以复用，接下来计划是支持multi-field的数据接入，会实现更高效的Sparse DeepFM, FNN, DIN, DIEN, 其实已经差不多了，现在正在弄可用性，希望能够通过配置文件直接串起整个流程。</p>


</div>

<br /><br />
<hr />

<div class="row clearfix">
  <div class="large-6 columns">
	<div class="text-left" style="padding:15px 0px;">
		
	        <a href="15536014868367.html"  title="Previous Post: ps-lite再一次研读源码">&laquo; ps-lite再一次研读源码</a>
	    
	</div>
  </div>
  <div class="large-6 columns">
	<div class="text-right" style="padding:15px 0px;">
		
	        <a href="Introduction%20to%20GAN.html" 
	        title="Next Post: 深度解析为什么GAN能是Structured Learning的一种解决方案">深度解析为什么GAN能是Structured Learning的一种解决方案 &raquo;</a>
	    
	</div>
  </div>
</div>

<div class="row">
<div style="padding:0px 0.93em;" class="share-comments">

</div>
</div>
<script type="text/javascript">
	$(function(){
		var currentURL = '15430699092916.html';
		$('#side-nav a').each(function(){
			if($(this).attr('href') == currentURL){
				$(this).parent().addClass('active');
			}
		});
	});
</script>  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    



  













<script src="asset/prism.js"></script>


<style type="text/css">
figure{margin: 0.4em 0;padding: 0;}
  figcaption{text-align:center;}

/* PrismJS 1.14.0
 http://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    text-shadow: 0 1px white;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
    
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
    
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
    text-shadow: none;
    background:#b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
    text-shadow: none;
    background: #b3d4fc;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background: #F7F7F7;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: slategray;
}

.token.punctuation {
    color: #999;
}

.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #9a6e3a;
    background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #07a;
}

.token.function,
.token.class-name {
    color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
    color: #e90;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
    position: relative;
    padding-left: 3.8em;
    counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
    position: relative;
    white-space: inherit;
}

.line-numbers .line-numbers-rows {
    position: absolute;
    pointer-events: none;
    top: 0;
    font-size: 100%;
    left: -3.8em;
    width: 3em; /* works for line-numbers below 1000 lines */
    letter-spacing: -1px;
    border-right: 1px solid #999;

    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

}

    .line-numbers-rows > span {
        pointer-events: none;
        display: block;
        counter-increment: linenumber;
    }

        .line-numbers-rows > span:before {
            content: counter(linenumber);
            color: #999;
            display: block;
            padding-right: 0.8em;
            text-align: right;
        }


</style>
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>


  </body>
</html>
