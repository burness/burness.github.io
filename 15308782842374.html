<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  炼丹师读源码之PaddlePaddle底层计算架构设计 - 小石头的码疯窝
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="小石头的码疯窝" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
 
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 小石头的码疯窝</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html">推荐系统</a></li>
        
            <li><a href="TensorFlow.html">TensorFlow</a></li>
        
            <li><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0.html">机器学习平台</a></li>
        
            <li><a href="%E5%9B%BE%E8%AE%A1%E7%AE%97.html">图计算</a></li>
        
            <li><a href="pytorch.html">pytorch</a></li>
        
            <li><a href="%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F.html">分布式系统</a></li>
        
            <li><a href="mlops.html">mlops</a></li>
        
            <li><a href="paddle.html">paddle</a></li>
        
            <li><a href="%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8.html">参数服务器</a></li>
        
            <li><a href="GAN.html">GAN</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		var currentURL = '15308782842374.html';
		currentURL = currentURL.substr(0,currentURL.length-5);
		$('#menu_item_'+currentURL).addClass('is_active');
	});
</script>
<div class="row">

    <div id="single-page-wrap">
        <h1>炼丹师读源码之PaddlePaddle底层计算架构设计</h1>

        <div class="markdown-body post-page">
        <ul>
<li><a href="#%E6%95%B0%E5%80%BC%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1">数值架构设计</a>
<ul>
<li><a href="#paddle-v2">Paddle V2</a></li>
<li><a href="#paddlefluid">PaddleFluid</a>
<ul>
<li><a href="#tensor%E6%9B%BF%E4%BB%A3matrix">Tensor替代Matrix</a></li>
</ul>
</li>
</ul>
</li>
</ul>

<h2><a id="%E6%95%B0%E5%80%BC%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1" class="anchor" aria-hidden="true" href="#%E6%95%B0%E5%80%BC%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="octicon octicon-link"></span></a>数值架构设计</h2>
<h3><a id="paddle-v2" class="anchor" aria-hidden="true" href="#paddle-v2"><span class="octicon octicon-link"></span></a>Paddle V2</h3>
<h3><a id="paddlefluid" class="anchor" aria-hidden="true" href="#paddlefluid"><span class="octicon octicon-link"></span></a>PaddleFluid</h3>
<h4><a id="tensor%E6%9B%BF%E4%BB%A3matrix" class="anchor" aria-hidden="true" href="#tensor%E6%9B%BF%E4%BB%A3matrix"><span class="octicon octicon-link"></span></a>Tensor替代Matrix</h4>
<p><strong>Placeholder与PlaceholderImpl</strong></p>
<pre><code>struct Placeholder {
    virtual ~Placeholder() = default;
    virtual void* ptr() const = 0;
    virtual size_t size() const = 0;
    virtual std::type_index type() const = 0;
    // place.h有相关定义
    virtual platform::Place place() const = 0;
    virtual void set_type(std::type_index type) = 0;
    virtual void set_place(platform::Place place) = 0;
};

struct PlaceholderImpl : public Placeholder {
    PlaceholderImpl(Place place, size_t size, std::type_index type)
        : ptr_(static_cast&lt;uint8_t*&gt;(memory::Alloc(place, size)),
            memory::PODDeleter&lt;uint8_t, Place&gt;(place)),
        place_(place),
        size_(size),
        type_(type) {
    PADDLE_ENFORCE_NOT_NULL(ptr_, &quot;Insufficient %s memory to allocation.&quot;,
                            (is_cpu_place(place_) ? &quot;CPU&quot; : &quot;GPU&quot;));
    }

    virtual size_t size() const { return size_; }
    virtual platform::Place place() const { return place_; }
    virtual void* ptr() const { return static_cast&lt;void*&gt;(ptr_.get()); }
    virtual std::type_index type() const { return type_; }
    virtual void set_type(std::type_index type) { type_ = type; }
    virtual void set_place(platform::Place place) { place_ = place; }

    /*! the pointer of memory block. */
    std::unique_ptr&lt;uint8_t, memory::PODDeleter&lt;uint8_t, Place&gt;&gt; ptr_;

    /*! the place of memory block. */
    platform::Place place_;

    /*! the size of memory block. */
    size_t size_;

    /* the current type of memory */
    std::type_index type_;
};
</code></pre>
<p><strong>DDim</strong></p>
<pre><code>struct DDim {
    // variant 联合体，multi type， single value， 这里的Dim&lt;0&gt;可以在下面看dim.h里结构体Dim的定义, 这里最多支持rank为9的维度，也就是说9维变量
    typedef boost::variant&lt;Dim&lt;0&gt;, Dim&lt;1&gt;, Dim&lt;2&gt;, Dim&lt;3&gt;, Dim&lt;4&gt;, Dim&lt;5&gt;, Dim&lt;6&gt;,
                            Dim&lt;7&gt;, Dim&lt;8&gt;, Dim&lt;9&gt;&gt;
        DDimVar;
    DDimVar var;

    DDim() : var(Dim&lt;1&gt;()) {}

    template &lt;int D&gt;
    explicit DDim(const Dim&lt;D&gt;&amp; in) : var(in) {}

    /*implicit*/ DDim(std::initializer_list&lt;int64_t&gt; init_list);

    template &lt;int D&gt;
    DDim&amp; operator=(const Dim&lt;D&gt;&amp; in) {
        var = in;
        return *this;
    }

    int64_t&amp; operator[](int idx);
    int64_t operator[](int idx) const;

    template &lt;typename Visitor&gt;
    typename Visitor::result_type apply_visitor(Visitor&amp; visitor) {
        return var.apply_visitor(visitor);
    }

    template &lt;typename Visitor&gt;
    typename Visitor::result_type apply_visitor(Visitor&amp; visitor) const {
        return var.apply_visitor(visitor);
    }

    DDimVar getVar() { return var; }

    bool operator==(DDim d) const;

    bool operator!=(DDim d) const;

    DDim operator+(DDim d) const;

    DDim operator*(DDim d) const;

    int size() const;
    };

// 从vector来创建DDim
DDim make_ddim(const std::vector&lt;int64_t&gt;&amp; dims);
Dim make_ddim(const std::vector&lt;int&gt;&amp; dims);

// 模板， i为维度
template &lt;int i&gt;
struct Dim {
    static constexpr int dimensions = i;

    template &lt;typename... Args&gt;
    HOSTDEVICE Dim(int64_t _head, Args... _tail) : head(_head), tail(_tail...) {
        static_assert(sizeof...(_tail) == i - 1,
                    &quot;Dim initialized with the wrong number of parameters&quot;);
    }

    HOSTDEVICE
    Dim(int64_t _head, const Dim&lt;i - 1&gt;&amp; _tail) : head(_head), tail(_tail) {}

    HOSTDEVICE
    Dim() : head(0), tail() {}

    /** Construct a Dim from a linear index and size.  Uses Fortran order
    * indexing. */
    HOSTDEVICE
    Dim(int64_t idx, const Dim&lt;i&gt;&amp; size)
        : head(idx % size.head), tail(idx / size.head, size.tail) {}

    /** Construct a Dim with each dimension set to the given index */
    HOSTDEVICE
    Dim(int64_t idx) : head(idx), tail(idx) {}

    HOSTDEVICE
    bool operator==(const Dim&lt;i&gt;&amp; o) const {
        return (head == o.head) &amp;&amp; (tail == o.tail);
    }

    HOSTDEVICE
    bool operator!=(const Dim&lt;i&gt;&amp; o) const { return !(*this == o); }

    HOSTDEVICE
    int64_t&amp; operator[](int idx);
    HOSTDEVICE
    int64_t operator[](int idx) const;

    HOST std::string to_string() const;

    int64_t head;
    Dim&lt;i - 1&gt; tail;
    };
</code></pre>
<p><strong>DataLayout</strong><br />
DataLayout用于支持不同的DataLayout,如何NHWC、HCHW，KAnyLayout、KMKLDNN等等；</p>
<pre><code>enum class DataLayout {
    kNHWC = 0,
    kNCHW = 1,
    kAnyLayout = 2,
    kMKLDNN = 3,  // all layouts supported by MKLDNN internally
    };
</code></pre>
<p><strong>Place</strong></p>
<pre><code>struct CPUPlace {
  // WORKAROUND: for some reason, omitting this constructor
  // causes errors with boost 1.59 and OSX
  CPUPlace() {}

  // needed for variant equality comparison
  inline bool operator==(const CPUPlace &amp;) const { return true; }
  inline bool operator!=(const CPUPlace &amp;) const { return false; }
};

struct CUDAPlace {
  CUDAPlace() : CUDAPlace(0) {}
  explicit CUDAPlace(int d) : device(d) {}

  inline int GetDeviceId() const { return device; }
  // needed for variant equality comparison
  inline bool operator==(const CUDAPlace &amp;o) const {
      return device == o.device;
  }
  inline bool operator!=(const CUDAPlace &amp;o) const { return !(*this == o); }

  int device;
};

struct CUDAPinnedPlace {
  CUDAPinnedPlace() {}

  // needed for variant equality comparison
  inline bool operator==(const CUDAPinnedPlace &amp;) const { return true; }
  inline bool operator!=(const CUDAPinnedPlace &amp;) const { return false; }
};
// visitor设计模式与boost static_visitor 模式 见 http://bitdewy.github.io/blog/2013/07/15/static-visitor/
struct IsCUDAPlace : public boost::static_visitor&lt;bool&gt; {
  bool operator()(const CPUPlace &amp;) const { return false; }
  bool operator()(const CUDAPlace &amp;gpu) const { return true; }
  bool operator()(const CUDAPinnedPlace &amp;) const { return false; }
};

struct IsCPUPlace : public boost::static_visitor&lt;bool&gt; {
  bool operator()(const CPUPlace &amp;cpu) const { return true; }
  bool operator()(const CUDAPlace &amp;) const { return false; }
  bool operator()(const CUDAPinnedPlace &amp;) const { return false; }
};

struct IsCUDAPinnedPlace : public boost::static_visitor&lt;bool&gt; {
  bool operator()(const CPUPlace &amp;) const { return false; }
  bool operator()(const CUDAPlace &amp;) const { return false; }
  bool operator()(const CUDAPinnedPlace &amp;cuda_pinned) const { return true; }
};

typedef boost::variant&lt;CUDAPlace, CPUPlace, CUDAPinnedPlace&gt; Place;

using PlaceList = std::vector&lt;Place&gt;;

void set_place(const Place &amp;);
const Place &amp;get_place();

const CUDAPlace default_gpu();
const CPUPlace default_cpu();
const CUDAPinnedPlace default_cuda_pinned();

bool is_gpu_place(const Place &amp;);
bool is_cpu_place(const Place &amp;);
bool is_cuda_pinned_place(const Place &amp;);
bool places_are_same_class(const Place &amp;, const Place &amp;);
bool is_same_place(const Place &amp;, const Place &amp;);

struct PlaceHash {
std::size_t operator()(const Place &amp;p) const {
    constexpr size_t num_dev_bits = 4;
    std::hash&lt;int&gt; ihash;
    size_t dev_id = 0;
    if (is_gpu_place(p)) {
      // 如果是gpu设备，则拿到对应的device id
      dev_id = boost::get&lt;CUDAPlace&gt;(p).device;
    }
    return ihash(dev_id &lt;&lt; num_dev_bits | p.which());
}
};

std::ostream &amp;operator&lt;&lt;(std::ostream &amp;, const Place &amp;);

template &lt;typename Visitor&gt;
struct PlaceVisitorWrapper
    : public boost::static_visitor&lt;typename Visitor::result_type&gt; {
const Visitor &amp;visitor_;
explicit PlaceVisitorWrapper(const Visitor &amp;visitor) : visitor_(visitor) {}

typename Visitor::result_type operator()(const CPUPlace &amp;cpu) const {
    return visitor_(cpu);
}

typename Visitor::result_type operator()(const CUDAPlace &amp;cuda) const {
#ifdef PADDLE_WITH_CUDA
    return visitor_(cuda);
#else
    PADDLE_THROW(&quot;Paddle is not compiled with CUDA. Cannot visit cuda device&quot;);
    return typename Visitor::result_type();
#endif
}

typename Visitor::result_type operator()(
    const CUDAPinnedPlace &amp;cuda_pinned) const {
#ifdef PADDLE_WITH_CUDA
    return visitor_(cuda_pinned);
#else
    PADDLE_THROW(&quot;Paddle is not compiled with CUDA. Cannot visit cuda_pinned&quot;);
    return typename Visitor::result_type();
#endif
}
};

template &lt;typename Visitor&gt;
typename Visitor::result_type VisitPlace(const Place &amp;place,
                                        const Visitor &amp;visitor) {
return boost::apply_visitor(PlaceVisitorWrapper&lt;Visitor&gt;(visitor), place);
}
</code></pre>
<p><strong>Tensor()</strong><br />
Tensor构造函数，包括参数为Place的构造函数，配置holder_为对应place。</p>
<pre><code>Tensor() : offset_(0) {}

/*! Constructor with place should only be used in pybind. */
explicit Tensor(const platform::Place&amp; place) : offset_(0) {
    holder_-&gt;set_place(place);
}
</code></pre>
<p><strong>data()</strong></p>
<p>data()返回内存块对应的指针：</p>
<pre><code>template &lt;typename T&gt;
inline const T* Tensor::data() const {
check_memory_size();
PADDLE_ENFORCE(std::is_same&lt;T, void&gt;::value ||
                    holder_-&gt;type() == std::type_index(typeid(T)),
                &quot;Tensor holds the wrong type, it holds %s&quot;,
                this-&gt;holder_-&gt;type().name());
// typedef unsigned long int uintptr_t;  
return reinterpret_cast&lt;const T*&gt;(
    reinterpret_cast&lt;uintptr_t&gt;(holder_-&gt;ptr()) + offset_);
}

template &lt;typename T&gt;
inline const T* Tensor::data() const {
check_memory_size();
PADDLE_ENFORCE(std::is_same&lt;T, void&gt;::value ||
                    holder_-&gt;type() == std::type_index(typeid(T)),
                &quot;Tensor holds the wrong type, it holds %s&quot;,
                this-&gt;holder_-&gt;type().name());

return reinterpret_cast&lt;const T*&gt;(
    reinterpret_cast&lt;uintptr_t&gt;(holder_-&gt;ptr()) + offset_);
}
</code></pre>
<p><strong>mutable_data()</strong></p>
<pre><code>void* Tensor::mutable_data(platform::Place place, std::type_index type) {
    if (holder_ != nullptr) {
        holder_-&gt;set_type(type);
    }
    PADDLE_ENFORCE_GE(numel(), 0,
                        &quot;When calling this method, the Tensor's numel must be &quot;
                        &quot;equal or larger than zero. &quot;
                        &quot;Please check Tensor::Resize has been called first.&quot;);
    int64_t size = numel() * SizeOfType(type);
    /* some versions of boost::variant don't have operator!= */
    if (holder_ == nullptr || !(holder_-&gt;place() == place) ||
        holder_-&gt;size() &lt; size + offset_) {
        if (platform::is_cpu_place(place)) {
        holder_.reset(new PlaceholderImpl&lt;platform::CPUPlace&gt;(
            boost::get&lt;platform::CPUPlace&gt;(place), size, type));
        } else if (platform::is_gpu_place(place) ||
                platform::is_cuda_pinned_place(place)) {
    #ifndef PADDLE_WITH_CUDA
        PADDLE_THROW(
            &quot;CUDAPlace or CUDAPinnedPlace is not supported in CPU-only mode.&quot;);
        }
    #else
        if (platform::is_gpu_place(place)) {
            holder_.reset(new PlaceholderImpl&lt;platform::CUDAPlace&gt;(
                boost::get&lt;platform::CUDAPlace&gt;(place), size, type));
        } else if (platform::is_cuda_pinned_place(place)) {
            holder_.reset(new PlaceholderImpl&lt;platform::CUDAPinnedPlace&gt;(
                boost::get&lt;platform::CUDAPinnedPlace&gt;(place), size, type));
        }
        }
    #endif
        offset_ = 0;
    }
    return reinterpret_cast&lt;void*&gt;(reinterpret_cast&lt;uintptr_t&gt;(holder_-&gt;ptr()) +
                                    offset_);
    }

    void* Tensor::mutable_data(platform::Place place) {
    PADDLE_ENFORCE(this-&gt;holder_ != nullptr,
                    &quot;Cannot invoke mutable data if current hold nothing.&quot;);
    return mutable_data(place, holder_-&gt;type());
    }
</code></pre>
<p><strong>dims()</strong><br />
<strong>numel()</strong><br />
<strong>Resize()</strong><br />
<strong>ShareDataWith()</strong><br />
<strong>Slice()</strong><br />
<strong>place()</strong><br />
<strong>type()</strong><br />
<strong>memory_size()</strong><br />
<strong>check_memory_size()</strong><br />
<strong>layout()</strong><br />
<strong>set_layout()</strong></p>

        </div>
    </div>
</div>              
 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>



  













<script src="asset/prism.js"></script>


<style type="text/css">
figure{margin: 0;padding: 0;}
figcaption{text-align:center;}

/* PrismJS 1.14.0
 http://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    text-shadow: 0 1px white;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
    
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
    
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
    text-shadow: none;
    background:#b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
    text-shadow: none;
    background: #b3d4fc;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background: #F7F7F7;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: slategray;
}

.token.punctuation {
    color: #999;
}

.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #9a6e3a;
    background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #07a;
}

.token.function,
.token.class-name {
    color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
    color: #e90;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
    position: relative;
    padding-left: 3.8em;
    counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
    position: relative;
    white-space: inherit;
}

.line-numbers .line-numbers-rows {
    position: absolute;
    pointer-events: none;
    top: 0;
    font-size: 100%;
    left: -3.8em;
    width: 3em; /* works for line-numbers below 1000 lines */
    letter-spacing: -1px;
    border-right: 1px solid #999;

    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

}

    .line-numbers-rows > span {
        pointer-events: none;
        display: block;
        counter-increment: linenumber;
    }

        .line-numbers-rows > span:before {
            content: counter(linenumber);
            color: #999;
            display: block;
            padding-right: 0.8em;
            text-align: right;
        }

</style>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>



  </body>
</html>
