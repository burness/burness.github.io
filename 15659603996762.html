<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Dive Into TensorFlow - 
  
  </title>
 <meta name="description" content="">
 <link href="atom.xml" rel="alternate" title="" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />

    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
    <script src="asset/highlightjs/highlight.pack.js"></script>
    <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
    <script>hljs.initHighlightingOnLoad();</script>
    
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>

<div id="header">
    <h1><a href="index.html"></a></h1>
</div>

</nav>
        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; </span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
      <li><a href="index.html">Home</a></li>
      
        <li class="divider"></li>
        <li><label>推荐系统</label></li>

          
            <li><a title="推荐系统的禅与道" href="15951226773958.html">推荐系统的禅与道</a></li>
          
            <li><a title="推荐系统灌水文之如何理解Item" href="15763400595374.html">推荐系统灌水文之如何理解Item</a></li>
          

      
        <li class="divider"></li>
        <li><label>TensorFlow</label></li>

          
            <li><a title="TensorFlow Sparse的一个优化" href="15768353446694.html">TensorFlow Sparse的一个优化</a></li>
          
            <li><a title="基础知识背景" href="15768070172080.html">基础知识背景</a></li>
          
            <li><a title="TensorFlow优化" href="15744799610685.html">TensorFlow优化</a></li>
          
            <li><a title="GDG上海 2019.10.13分享内容准备" href="15673444950441.html">GDG上海 2019.10.13分享内容准备</a></li>
          
            <li><a title="Dive Into TensorFlow" href="15659603996762.html">Dive Into TensorFlow</a></li>
          
            <li><a title="Maybe Best Practice With Sparse Machine Learning In TensorFlow" href="15430699092916.html">Maybe Best Practice With Sparse Machine Learning In TensorFlow</a></li>
          

      
        <li class="divider"></li>
        <li><label>机器学习平台</label></li>

          
            <li><a title="---" href="16533711069508.html">---</a></li>
          
            <li><a title="机器学习平台在云音乐的持续实践" href="16371350579612.html">机器学习平台在云音乐的持续实践</a></li>
          
            <li><a title="泛模型管理与分发" href="16076083666793.html">泛模型管理与分发</a></li>
          
            <li><a title="机器学习与容器化平台" href="15861773530303.html">机器学习与容器化平台</a></li>
          
            <li><a title="机器学习工程实践" href="15648106167930.html">机器学习工程实践</a></li>
          

      
        <li class="divider"></li>
        <li><label>图计算</label></li>

          
            <li><a title="直播场景PGL落地" href="16078481811620.html">直播场景PGL落地</a></li>
          
            <li><a title="Graph Neural Networks" href="16077533959046.html">Graph Neural Networks</a></li>
          
            <li><a title="graph representation learning" href="16077533959085.html">graph representation learning</a></li>
          
            <li><a title="Spectral Clustering" href="16029890553575.html">Spectral Clustering</a></li>
          
            <li><a title="Community structure in networks" href="16019601035128.html">Community structure in networks</a></li>
          
            <li><a title="Motifs and structural roles in networks" href="16017096445579.html">Motifs and structural roles in networks</a></li>
          
            <li><a title="Properties of Networks and Random Graph Model" href="16016274752497.html">Properties of Networks and Random Graph Model</a></li>
          

      
        <li class="divider"></li>
        <li><label>pytorch</label></li>

          
            <li><a title="pytorch 环境安装及配置" href="15808187045354.html">pytorch 环境安装及配置</a></li>
          

      
        <li class="divider"></li>
        <li><label>分布式系统</label></li>

          
            <li><a title="分布式一致性" href="15860748439491.html">分布式一致性</a></li>
          
            <li><a title="raft 参考文章" href="15854050053037.html">raft 参考文章</a></li>
          
            <li><a title="分布式系统书籍" href="15853877486542.html">分布式系统书籍</a></li>
          
            <li><a title="容灾【备份】" href="15848127872361.html">容灾【备份】</a></li>
          
            <li><a title="容灾【备份】" href="15848127093419.html">容灾【备份】</a></li>
          

      
        <li class="divider"></li>
        <li><label>mlops</label></li>

          
            <li><a title="模型生产环境中的反馈与数据回流" href="16490569390259.html">模型生产环境中的反馈与数据回流</a></li>
          
            <li><a title="mlops之监控与数据回流" href="16482627913984.html">mlops之监控与数据回流</a></li>
          
            <li><a title="为机器学习量身定做的ops工具：cml & dvc" href="16268581441013.html">为机器学习量身定做的ops工具：cml & dvc</a></li>
          
            <li><a title="[toc]" href="16003962131575.html">[toc]</a></li>
          

      
        <li class="divider"></li>
        <li><label>paddle</label></li>

          
            <li><a title="直播场景PGL落地" href="16078655202819.html">直播场景PGL落地</a></li>
          

      
        <li class="divider"></li>
        <li><label>参数服务器</label></li>

          
            <li><a title="ps-lite" href="15836784836219.html">ps-lite</a></li>
          
            <li><a title="ps-lite再一次研读源码" href="15536014868367.html">ps-lite再一次研读源码</a></li>
          

      
        <li class="divider"></li>
        <li><label>GAN</label></li>

          
            <li><a title="深度解析为什么GAN能是Structured Learning的一种解决方案" href="Introduction%20to%20GAN.html">深度解析为什么GAN能是Structured Learning的一种解决方案</a></li>
          

      
      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>

        <section id="main-content" role="main" class="scroll-container">

          <div class="row">
            <div class="large-3 medium-3 columns">
              <div class="hide-for-small">
                <div class="sidebar">
                <nav>
                  <ul id="side-nav" class="side-nav">

                    
                      <li class="side-title"><span>推荐系统</span></li>
                        
                          <li><a title="推荐系统的禅与道" href="15951226773958.html">推荐系统的禅与道</a></li>
                        
                          <li><a title="推荐系统灌水文之如何理解Item" href="15763400595374.html">推荐系统灌水文之如何理解Item</a></li>
                        

                    
                      <li class="side-title"><span>TensorFlow</span></li>
                        
                          <li><a title="TensorFlow Sparse的一个优化" href="15768353446694.html">TensorFlow Sparse的一个优化</a></li>
                        
                          <li><a title="基础知识背景" href="15768070172080.html">基础知识背景</a></li>
                        
                          <li><a title="TensorFlow优化" href="15744799610685.html">TensorFlow优化</a></li>
                        
                          <li><a title="GDG上海 2019.10.13分享内容准备" href="15673444950441.html">GDG上海 2019.10.13分享内容准备</a></li>
                        
                          <li><a title="Dive Into TensorFlow" href="15659603996762.html">Dive Into TensorFlow</a></li>
                        
                          <li><a title="Maybe Best Practice With Sparse Machine Learning In TensorFlow" href="15430699092916.html">Maybe Best Practice With Sparse Machine Learning In TensorFlow</a></li>
                        

                    
                      <li class="side-title"><span>机器学习平台</span></li>
                        
                          <li><a title="---" href="16533711069508.html">---</a></li>
                        
                          <li><a title="机器学习平台在云音乐的持续实践" href="16371350579612.html">机器学习平台在云音乐的持续实践</a></li>
                        
                          <li><a title="泛模型管理与分发" href="16076083666793.html">泛模型管理与分发</a></li>
                        
                          <li><a title="机器学习与容器化平台" href="15861773530303.html">机器学习与容器化平台</a></li>
                        
                          <li><a title="机器学习工程实践" href="15648106167930.html">机器学习工程实践</a></li>
                        

                    
                      <li class="side-title"><span>图计算</span></li>
                        
                          <li><a title="直播场景PGL落地" href="16078481811620.html">直播场景PGL落地</a></li>
                        
                          <li><a title="Graph Neural Networks" href="16077533959046.html">Graph Neural Networks</a></li>
                        
                          <li><a title="graph representation learning" href="16077533959085.html">graph representation learning</a></li>
                        
                          <li><a title="Spectral Clustering" href="16029890553575.html">Spectral Clustering</a></li>
                        
                          <li><a title="Community structure in networks" href="16019601035128.html">Community structure in networks</a></li>
                        
                          <li><a title="Motifs and structural roles in networks" href="16017096445579.html">Motifs and structural roles in networks</a></li>
                        
                          <li><a title="Properties of Networks and Random Graph Model" href="16016274752497.html">Properties of Networks and Random Graph Model</a></li>
                        

                    
                      <li class="side-title"><span>pytorch</span></li>
                        
                          <li><a title="pytorch 环境安装及配置" href="15808187045354.html">pytorch 环境安装及配置</a></li>
                        

                    
                      <li class="side-title"><span>分布式系统</span></li>
                        
                          <li><a title="分布式一致性" href="15860748439491.html">分布式一致性</a></li>
                        
                          <li><a title="raft 参考文章" href="15854050053037.html">raft 参考文章</a></li>
                        
                          <li><a title="分布式系统书籍" href="15853877486542.html">分布式系统书籍</a></li>
                        
                          <li><a title="容灾【备份】" href="15848127872361.html">容灾【备份】</a></li>
                        
                          <li><a title="容灾【备份】" href="15848127093419.html">容灾【备份】</a></li>
                        

                    
                      <li class="side-title"><span>mlops</span></li>
                        
                          <li><a title="模型生产环境中的反馈与数据回流" href="16490569390259.html">模型生产环境中的反馈与数据回流</a></li>
                        
                          <li><a title="mlops之监控与数据回流" href="16482627913984.html">mlops之监控与数据回流</a></li>
                        
                          <li><a title="为机器学习量身定做的ops工具：cml & dvc" href="16268581441013.html">为机器学习量身定做的ops工具：cml & dvc</a></li>
                        
                          <li><a title="[toc]" href="16003962131575.html">[toc]</a></li>
                        

                    
                      <li class="side-title"><span>paddle</span></li>
                        
                          <li><a title="直播场景PGL落地" href="16078655202819.html">直播场景PGL落地</a></li>
                        

                    
                      <li class="side-title"><span>参数服务器</span></li>
                        
                          <li><a title="ps-lite" href="15836784836219.html">ps-lite</a></li>
                        
                          <li><a title="ps-lite再一次研读源码" href="15536014868367.html">ps-lite再一次研读源码</a></li>
                        

                    
                      <li class="side-title"><span>GAN</span></li>
                        
                          <li><a title="深度解析为什么GAN能是Structured Learning的一种解决方案" href="Introduction%20to%20GAN.html">深度解析为什么GAN能是Structured Learning的一种解决方案</a></li>
                        

                    
                  </ul>
                </nav>
                </div>
              </div>
            </div>
            <div class="large-9 medium-9 columns">

 <div class="markdown-body">
<h1>Dive Into TensorFlow</h1>

<p>前一段时间，一直在忙框架方面的工作，偶尔也会帮业务同学去优化优化使用TensorFlow的代码，也加上之前看了dmlc/relay，nnvm的代码，觉得蛮有意思，也想分别看下TensorFlow的Graph IR、PaddlePaddle的Graph IR，上周五，看代码看的正津津有味的时候，看到某个数据竞赛群里面讨论东西，不记得具体内容，大概说的是框架的代码实现， 有几位算法大佬说看底层源码比较麻烦，因为比较早从框架，这块代码通常都还能看，问题都不大，和群里小伙伴吹水了半天之后，感觉是可以写篇如何看TensorFlow或者其他框架底层源码的劝退文了。</p>
<h2><a id="%E5%88%A9%E5%85%B6%E5%99%A8" class="anchor" aria-hidden="true" href="#%E5%88%A9%E5%85%B6%E5%99%A8"><span class="octicon octicon-link"></span></a>利其器</h2>
<p>首先，一定是要找个好工作来看源码，很多人推荐vs code、sublime，我试过vs code+bazel的，好像也不错，但是后面做c++适应了clion之后，除了资源要求比较多，还是蛮不错的，使用c++一般推荐使用cmake来看编译项目，但是TensorFlow是bazel的，无法直接支持，最开始，这边是自己写简单的cmake，能够实现简单的代码跳转，但是涉及到比如protobuf之类的编译过后产生的文件无法跳转，比较麻烦，不够纯粹，很早之前知道clion有bazel的组件，但是不知道为啥一直搞不通，上周找时间再试了试，发现竟然通了，使用之后，这才是看tf源码的真正方式：</p>
<p>首先，选择合适版本的bazel，千万不能太高，也不能太低，这里我拉的是TF2.0的代码，使用bazel 0.24.0刚刚好，切记<strong>千万别太高也比太低</strong>, <strong>千万别太高也比太低</strong>,<strong>千万别太高也比太低</strong>。<br />
<img src="media/15659603996762/15659628687353.jpg" alt="" /><br />
其次，clion上选择bazel的插件<br />
<img src="media/15659603996762/15659629695664.jpg" alt="" /></p>
<p>第三步，./configure，然后按你的意图选择合适的编译配置<br />
<img src="media/15659603996762/15659638684743.jpg" alt="" /><br />
第四步，导入bazel项目：File=&gt;<br />
<img src="media/15659603996762/15659642008062.jpg" alt="" /><br />
<img src="media/15659603996762/15659642657296.jpg" alt="" /><br />
<img src="media/15659603996762/15659642784560.jpg" alt="" /><br />
经过上面几步之后，接下来就要经过比较长时间的等待，clion会导入bazel项目，然后编译整个项目，这个耗时视你机器和网络而定（顺便提一句，最好保证比较畅通的访问github的网络，另外由于上面targets:all，会编译TensorFlow所有的项目，如果你知道是什么意思，可以自己修改，如果不知道的话我先不提了，默认就好，期间会有很多Error出现，放心，问题不大，因为会默认编译所有的模块）<br />
经过上面之后，我们就可以愉快的看代码啦，连protobuf生成的文件都很开心的跳转啦<br />
<img src="media/15659603996762/15659647731889.jpg" alt="" /><br />
<img src="media/15659603996762/15659648092985.jpg" alt="" /></p>
<h2><a id="%E6%9E%81%E7%AE%80%E7%89%88c%E5%85%A5%E9%97%A8" class="anchor" aria-hidden="true" href="#%E6%9E%81%E7%AE%80%E7%89%88c%E5%85%A5%E9%97%A8"><span class="octicon octicon-link"></span></a>极简版c++入门</h2>
<p>TensorFlow大部分人都知道，底层是c++写的，然后外面包了一层python的api，既然底层是c++写的，那么用c++也是可以用来训练模型的，大部分人应该都用过c++或者java去载入frozen的模型，然后做serving应用在业务系统上，应该很少人去使用c++来训练模型，既然我们这里要读代码，我们先尝试看看用c++写模型，文件路径如下图：<br />
<img src="media/15659603996762/15659654881906.jpg" alt="" /><br />
主要函数就那么几个：CreateGraphDef， ConcurrentSteps， ConcurrentSessions：</p>
<p><strong>CreateGraphDef</strong> 构造计算图</p>
<pre><code>GraphDef CreateGraphDef() {
  // TODO(jeff,opensource): This should really be a more interesting
  // computation.  Maybe turn this into an mnist model instead?
  Scope root = Scope::NewRootScope();
  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)

  // A = [3 2; -1 0].  Using Const&lt;float&gt; means the result will be a
  // float tensor even though the initializer has integers.
  auto a = Const&lt;float&gt;(root, {{3, 2}, {-1, 0}});

  // x = [1.0; 1.0]
  auto x = Const(root.WithOpName(&quot;x&quot;), {{1.f}, {1.f}});

  // y = A * x
  auto y = MatMul(root.WithOpName(&quot;y&quot;), a, x);

  // y2 = y.^2
  auto y2 = Square(root, y);

  // y2_sum = sum(y2).  Note that you can pass constants directly as
  // inputs.  Sum() will automatically create a Const node to hold the
  // 0 value.
  auto y2_sum = Sum(root, y2, 0);

  // y_norm = sqrt(y2_sum)
  auto y_norm = Sqrt(root, y2_sum);

  // y_normalized = y ./ y_norm
  Div(root.WithOpName(&quot;y_normalized&quot;), y, y_norm);

  GraphDef def;
  TF_CHECK_OK(root.ToGraphDef(&amp;def));

  return def;
}
</code></pre>
<p>定义graph 节点 root， 然后定义常数变量a (shape为2*2), x (shape为2* 1)，然后  y = A * x， y2 = y.^2， y2_sum = sum(y2)， y_norm = sqrt(y2_sum), y_normlized = y ./ y_norm。代码很简洁， 看起来一目了然,<br />
然后是ConcurrentSteps</p>
<pre><code>void ConcurrentSteps(const Options* opts, int session_index) {
  // Creates a session.
  SessionOptions options;
  std::unique_ptr&lt;Session&gt; session(NewSession(options));
  GraphDef def = CreateGraphDef();
  if (options.target.empty()) {
    graph::SetDefaultDevice(opts-&gt;use_gpu ? &quot;/device:GPU:0&quot; : &quot;/cpu:0&quot;, &amp;def);
  }

  TF_CHECK_OK(session-&gt;Create(def));

  // Spawn M threads for M concurrent steps.
  const int M = opts-&gt;num_concurrent_steps;
  std::unique_ptr&lt;thread::ThreadPool&gt; step_threads(
      new thread::ThreadPool(Env::Default(), &quot;trainer&quot;, M));

  for (int step = 0; step &lt; M; ++step) {
    step_threads-&gt;Schedule([&amp;session, opts, session_index, step]() {
      // Randomly initialize the input.
      Tensor x(DT_FLOAT, TensorShape({2, 1}));
      auto x_flat = x.flat&lt;float&gt;();
      x_flat.setRandom();
      std::cout &lt;&lt; &quot;x_flat: &quot; &lt;&lt; x_flat &lt;&lt; std::endl;
      Eigen::Tensor&lt;float, 0, Eigen::RowMajor&gt; inv_norm =
          x_flat.square().sum().sqrt().inverse();
      x_flat = x_flat * inv_norm();

      // Iterations.
      std::vector&lt;Tensor&gt; outputs;
      for (int iter = 0; iter &lt; opts-&gt;num_iterations; ++iter) {
        outputs.clear();
        TF_CHECK_OK(
            session-&gt;Run({{&quot;x&quot;, x}}, {&quot;y:0&quot;, &quot;y_normalized:0&quot;}, {}, &amp;outputs));
        CHECK_EQ(size_t{2}, outputs.size());

        const Tensor&amp; y = outputs[0];
        const Tensor&amp; y_norm = outputs[1];
        // Print out lambda, x, and y.
        std::printf(&quot;%06d/%06d %s\n&quot;, session_index, step,
                    DebugString(x, y).c_str());
        // Copies y_normalized to x.
        x = y_norm;
      }
    });
  }

  // Delete the threadpool, thus waiting for all threads to complete.
  step_threads.reset(nullptr);
  TF_CHECK_OK(session-&gt;Close());
}
</code></pre>
<p>新建一个session，然后设置10个线程来计算，来执行：</p>
<pre><code>std::vector&lt;Tensor&gt; outputs;
      for (int iter = 0; iter &lt; opts-&gt;num_iterations; ++iter) {
        outputs.clear();
        TF_CHECK_OK(
            session-&gt;Run({{&quot;x&quot;, x}}, {&quot;y:0&quot;, &quot;y_normalized:0&quot;}, {}, &amp;outputs));
        CHECK_EQ(size_t{2}, outputs.size());

        const Tensor&amp; y = outputs[0];
        const Tensor&amp; y_norm = outputs[1];
        // Print out lambda, x, and y.
        std::printf(&quot;%06d/%06d %s\n&quot;, session_index, step,
                    DebugString(x, y).c_str());
        // Copies y_normalized to x.
        x = y_norm;
      }
</code></pre>
<p>每次计算之后，x=y_norm，这里的逻辑其实就是为了计算矩阵A的最大eigenvalue， 重复执行x = y/y_norm; y= A*x;<br />
编译:</p>
<pre><code>bazel build //tensorflow/cc:tutorials_example_trainer 
</code></pre>
<p>执行结果，前面不用太care是我打印的一些调试输出：<br />
<img src="media/15659603996762/15659710663019.jpg" alt="" /></p>
<h2><a id="%E7%AE%80%E5%8D%95%E7%9A%84%E5%88%86%E6%9E%90" class="anchor" aria-hidden="true" href="#%E7%AE%80%E5%8D%95%E7%9A%84%E5%88%86%E6%9E%90"><span class="octicon octicon-link"></span></a>简单的分析</h2>
<p>上面简单的c++入门实例之后，可以抽象出TensorFlow的逻辑：</p>
<ol>
<li>构造graphdef，使用TensorFlow本身的Graph API，利用算子去构造一个逻辑计算的graph，可以试上述简单地计算eigenvalue，也可以是复杂的卷积网络，这里是涉及到Graph IR的东西，想要了解的话，我建议先看下nnvm和relay，才会有初步的概念；</li>
<li>用于构造graphdef的各种操作，比如上述将达到的Square、MatMul，这些操作可以是自己写的一些数学操作也可以是TensorFlow本身封装一些数学计算操作，可以是MKL的封装，也可以是cudnn的封装，当然也可以是非数学库，如TFRecord的读取；</li>
<li>Session的构造，新建一个session，然后用于graph外与graph内部的数据交互：session-&gt;Run({{&quot;x&quot;, x}}, {&quot;y:0&quot;, &quot;y_normalized:0&quot;}, {}, &amp;outputs));这里不停地把更新的x王graph里喂来计算y与y_normalized，然后将x更新为y_normalized；</li>
</ol>
<p>GraphDef这一套，太过复杂，不适合演示如何看TF源码，建议大家先有一定的基础知识之后，再看，这里我们摘出一些算法同学感兴趣的，比如Square这个怎么在TF当中实现以及绑定到对应操作</p>
<ol>
<li>代码中直接跳转到Square类，如下图；<br />
<img src="media/15659603996762/15659720353161.jpg" alt="" /></li>
<li>很明显看到Square类的定义，其构造函数，接收一个scope还有一个input， 然后我们找下具体实现，如下图：<br />
<img src="media/15659603996762/15659720529366.jpg" alt="" /></li>
<li>同目录下， math_ops.cc，看实现逻辑，我们是构造一个名为Square的op，然后往scope里更新，既然如此，肯定是预先有保存名为Square的op，接下来我们看下图：<br />
<img src="media/15659603996762/188061565535890_.pic_hd.jpg" alt="188061565535890_.pic_hd" /></li>
<li>这里讲functor::square注册到&quot;Square&quot;下，且为UnaryOp，这个我不知道怎么解释，相信用过eigen的人都知道，不知道的话去google下，很容易理解，且支持各种数据类型；<br />
<img src="media/15659603996762/188641565536482_.pic_hd.jpg" alt="188641565536482_.pic_hd" /></li>
<li>那么看起来，square的实现就在functor::square，我们再进去看看，集成base模板类，且看起来第二个模板参数为其实现的op，再跳转看看：<br />
<img src="media/15659603996762/188941565536836_.pic.jpg" alt="188941565536836_.pi" /><br />
6.最后，我们到达了最终的实现逻辑：operator()和packetOp，也看到了最终的实现，是不是没有想象的那么难。<br />
<img src="media/15659603996762/188951565536836_.pic.jpg" alt="188951565536836_.pi" /></li>
</ol>
<h2><a id="%E6%9B%B4%E9%87%8D%E8%A6%81%E4%B8%80%E7%82%B9" class="anchor" aria-hidden="true" href="#%E6%9B%B4%E9%87%8D%E8%A6%81%E4%B8%80%E7%82%B9"><span class="octicon octicon-link"></span></a>更重要一点</h2>
<p>看完了上面那些，基本上会知道怎么去看TensorFlow的一些基础的代码，如果你了解graph ir这套，可以更深入去理解下，这个过程中，如果对TensorFlow各个文件逻辑感兴趣，不妨去写写测试用例，TensorFlow很多源码文件都有对应的test用例，我们可以通过Build文件来查看，比如我想跑下client_session_test.cc这里的测试用例<br />
<img src="media/15659603996762/15659731117208.jpg" alt="" /><br />
我们看一下Build文件中<br />
<img src="media/15659603996762/15659731382718.jpg" alt="" /><br />
这里表明了对应的编译规则，然后我们只需要</p>
<pre><code>bazel build //tensorflow/cc:client_client_session_test
</code></pre>
<p><img src="media/15659603996762/15659732839186.jpg" alt="" /></p>
<p>然后运行相应的测试程序即可<br />
<img src="media/15659603996762/15659733184801.jpg" alt="" /></p>
<h2><a id="%E6%9B%B4%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%80%E7%82%B9" class="anchor" aria-hidden="true" href="#%E6%9B%B4%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%80%E7%82%B9"><span class="octicon octicon-link"></span></a>更更重要的一点</h2>
<p>上面把如何看TensorFlow代码的小经验教给各位，但是其实这个只是真正的开始，无论TensorFlow、MXNet、PaddlePaddle异或是TVM这些，单纯去看代码，很难理解深刻其中原理，需要去找相关行业的paper，以及找到行业的精英去请教，去学习。目前网上ml system的资料还是蛮多的，有点『乱花迷人眼』的感觉，也没有太多的课程来分享这块的工作，十分期望这些框架的官方分享这些框架的干货，之后我也会在学习中总结一些资料，有机会的话分享给大家。最后，这些东西确实是很复杂，作者在这块也是还是懵懵懂懂，希望能花时间把这些内在的东西搞清楚，真的还蛮有意思的。</p>


</div>

<br /><br />
<hr />

<div class="row clearfix">
  <div class="large-6 columns">
	<div class="text-left" style="padding:15px 0px;">
		
	        <a href="15673444950441.html"  title="Previous Post: GDG上海 2019.10.13分享内容准备">&laquo; GDG上海 2019.10.13分享内容准备</a>
	    
	</div>
  </div>
  <div class="large-6 columns">
	<div class="text-right" style="padding:15px 0px;">
		
	        <a href="15648106167930.html" 
	        title="Next Post: 机器学习工程实践">机器学习工程实践 &raquo;</a>
	    
	</div>
  </div>
</div>

<div class="row">
<div style="padding:0px 0.93em;" class="share-comments">

</div>
</div>
<script type="text/javascript">
	$(function(){
		var currentURL = '15659603996762.html';
		$('#side-nav a').each(function(){
			if($(this).attr('href') == currentURL){
				$(this).parent().addClass('active');
			}
		});
	});
</script>  
</div></div>


<div class="page-bottom">
  <div class="row">
  <hr />
  <div class="small-9 columns">
  <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
  <div class="small-3 columns">
  <p class="copyright text-right"><a href="#header">TOP</a></p>
  </div>
   
  </div>
</div>

        </section>
      </div>
    </div>
    



  













<script src="asset/prism.js"></script>


<style type="text/css">
figure{margin: 0.4em 0;padding: 0;}
  figcaption{text-align:center;}

/* PrismJS 1.14.0
 http://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    text-shadow: 0 1px white;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
    
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
    
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
    text-shadow: none;
    background:#b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
    text-shadow: none;
    background: #b3d4fc;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background: #F7F7F7;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: slategray;
}

.token.punctuation {
    color: #999;
}

.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #9a6e3a;
    background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #07a;
}

.token.function,
.token.class-name {
    color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
    color: #e90;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
    position: relative;
    padding-left: 3.8em;
    counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
    position: relative;
    white-space: inherit;
}

.line-numbers .line-numbers-rows {
    position: absolute;
    pointer-events: none;
    top: 0;
    font-size: 100%;
    left: -3.8em;
    width: 3em; /* works for line-numbers below 1000 lines */
    letter-spacing: -1px;
    border-right: 1px solid #999;

    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

}

    .line-numbers-rows > span {
        pointer-events: none;
        display: block;
        counter-increment: linenumber;
    }

        .line-numbers-rows > span:before {
            content: counter(linenumber);
            color: #999;
            display: block;
            padding-right: 0.8em;
            text-align: right;
        }


</style>
    
    <script src="asset/js/foundation.min.js"></script>
    <script src="asset/js/foundation/foundation.offcanvas.js"></script>
    <script>
      $(document).foundation();

     
    </script>


  </body>
</html>
